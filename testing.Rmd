---
title             : "Influence of Parsimony and Work-related Psychological Constructs in Predicting Turnover Intention when Using Machine Learning VS Regression"
shorttitle        : "Influence of Parsimony"
author: 
  - name          : "Diego Figueiras"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Dickson Hall 226"
    email         : "figueirasd1@montclair.edu"
affiliation:
  - id            : "1"
    institution   : "Montclai State University"

keywords          : "Employee turnover, machine learning"
wordcount         : "X"
bibliography      : ["articles.bib", "references.bib", "r-references.bib"]
floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : no
mask              : no
draft             : no
csl               : "apa7.csl"
documentclass     : "apa7"
classoption       : "man"
output            : papaja::apa6_pdf

---

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Etiam dignissim ullamcorper elementum. Curabitur nec lorem tristique, varius tellus ac, laoreet nisl. Nullam porttitor lacus id diam maximus vestibulum. Pellentesque euismod odio a pellentesque tincidunt. In aliquet at purus in commodo. Morbi consequat erat nisi, ut auctor libero facilisis vel. Aliquam vitae lectus ante. Etiam vel risus nec nisi posuere posuere non at tortor. Fusce sed dictum metus, id dignissim leo. Nulla placerat mattis dapibus.

Praesent faucibus nisl eros, eget interdum felis placerat id. In vitae mi efficitur, vulputate ligula a, dignissim eros. Nulla sit amet turpis quis turpis sollicitudin commodo. Aenean nibh diam, mattis in feugiat sit amet, sagittis et mi. Donec nec tristique dolor. Cras id porttitor lectus. Nullam a dui lorem. Vestibulum massa augue, imperdiet sit amet efficitur id, posuere id dolor. In nec laoreet tortor, in aliquam justo. Sed nec molestie felis. Nunc sed mi eget enim tempor venenatis.

Fusce vel erat ex. Etiam pulvinar purus nisi, nec vulputate nunc eleifend ac. Aliquam aliquet mi ut justo vestibulum, id sodales neque vehicula. Ut non consectetur nibh. Donec porta eget ligula nec mollis. Donec hendrerit ex a justo vestibulum, interdum sollicitudin dui venenatis. Mauris at egestas felis. Praesent semper urna magna, ultrices faucibus magna commodo vel.

Ut congue sem ut faucibus vulputate. Pellentesque at enim vitae leo vestibulum interdum quis non risus. Proin nec augue feugiat lorem porttitor accumsan. Suspendisse potenti. Vestibulum semper vehicula condimentum. Ut lobortis neque posuere, elementum dolor eu, varius tortor. Praesent mollis diam non rutrum malesuada. Donec quis aliquet lacus. Proin eleifend ipsum vel leo imperdiet iaculis. Praesent ut pharetra eros. Sed at consequat metus. Maecenas tempor nibh in dui consectetur, eget finibus massa pretium.

Nulla posuere, leo vel convallis varius, risus orci semper ante, non auctor eros nisi eu diam. Ut egestas pretium leo, vel pulvinar neque consequat id. Nullam pellentesque bibendum tortor eget pretium. Aliquam ultricies velit leo, at lacinia massa posuere eu. Donec placerat tellus vitae eros efficitur, ut tempus augue ultricies. Maecenas nunc tortor, blandit in felis vitae, suscipit interdum elit. Nulla facilisis, lorem sed scelerisque rhoncus, nisl metus tincidunt nisl, vel accumsan urna mi sit amet tellus. Aenean nibh libero, dignissim et mattis nec, luctus in neque.




```{r}

knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE)


```


```{r logitable100k, message=FALSE, warning=FALSE}
library(tidyverse)
library(papaja)
# Load necessary packages or install if not already installed
if (!require(knitr)) {
    install.packages("knitr")
    library(knitr)
}
library(kableExtra)
# Create a data frame with the classification report metrics
# metrics <- data.frame(
#   Class = c('0', '1', 'Accuracy', 'Macro Avg', 'Weighted Avg'),
#   Precision = c(0.71, 0.78, NA, 0.74, 0.75),
#   Recall = c(0.45, 0.91, NA, 0.68, 0.76),
#   `F1-Score` = c(0.55, 0.84, 0.76, 0.69, 0.75),
#   Support = c(11812, 24862, 36674, 36674, 36674)
# )

metrics<- read.csv("logi100k.csv")
logi100k<-data.frame(
  Algorithm = "logi100k",
  Model = "Logistic Regression",
  `Sample Size`= 100000,
  `Number of Variables` = 105,
  `AUC Score` = round(metrics$AUC[1], 3)
)

# Convert numeric values to text to handle NA values
metricsLOGI <- data.frame(lapply(metrics, function(x) ifelse(is.na(x), "", x)), stringsAsFactors = FALSE)
metricsLOGI[2:7]<- mutate_all(metricsLOGI[2:7], function(x) as.numeric(as.character(x)))
metricsLOGI <- data.frame(lapply(metricsLOGI, function(x) {
  if(is.numeric(x)) round(x, 3) else x
}))

# Adjust column names for the table
colnames(metrics)[1] <- ""

# Use kable to create a nicer table
apa_table(
  metrics
  , caption = "Logistic Regression Predictive Metrics"
  , note = "1= turnover intention, 0= no turnover intention."
  #, align = c("m{2cm}", "m{12cm}")
  #, longtable = TRUE
  , landscape = FALSE
  , escape = FALSE
)


# kable(metrics, caption = "Logistic Regression Predictive Metrics", 
#       col.names = c('Class', 'Precision', 'Recall', 'F1-Score', 'Support'), 
#       align = 'c') %>%
#   kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), 
#                 full_width = F, font_size = 12)


```



```{r xgbtable100k, message=FALSE, warning=FALSE}

# Load necessary packages or install if not already installed
if (!require(knitr)) {
    install.packages("knitr")
    library(knitr)
}
library(kableExtra)
# Create a data frame with the classification report metrics
# metrics <- data.frame(
#   Class = c('0', '1', 'Accuracy', 'Macro Avg', 'Weighted Avg'),
#   Precision = c(0.70, 0.78, NA, 0.74, 0.76),
#   Recall = c(0.48, 0.90, NA, 0.69, 0.77),
#   `F1-Score` = c(0.57, 0.84, 0.77, 0.70, 0.75),
#   Support = c(11812, 24862, 36674, 36674, 36674)
# )

metrics<- read.csv("xgb100k.csv")
xgb100k<-data.frame(
  Algorithm = "xgb100k",
  Model = "xgboosting",
  `Sample Size`= 100000,
  `Number of Variables` = 105,
  `AUC Score` = round(metrics$AUC[1], 3)
)


# Convert numeric values to text to handle NA values
metricsXGB <- data.frame(lapply(metrics, function(x) ifelse(is.na(x), "", x)), stringsAsFactors = FALSE)
metricsXGB[2:7]<- mutate_all(metricsXGB[2:7], function(x) as.numeric(as.character(x)))
metricsXGB <- data.frame(lapply(metricsXGB, function(x) {
  if(is.numeric(x)) round(x, 3) else x
}))

# Adjust column names for the table
colnames(metricsXGB)[1] <- ""

apa_table(
  metricsXGB
  , caption = "xgboosting Predictive Metrics"
  , note = "1= turnover intention, 0= no turnover intention."
  #, align = c("m{2cm}", "m{12cm}")
  #, longtable = TRUE
  , landscape = FALSE
  , escape = FALSE
)

# Use kable to create a nicer table
# kable(metricsXGB, caption = "xgboosting Predictive Metrics", 
#       col.names = c('Class', 'Precision', 'Recall', 'F1-Score', 'Support'), 
#       align = 'c') %>%
#   kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), 
#                 full_width = F, font_size = 12)


```



```{r nn100k, message=FALSE, warning=FALSE}

# Load necessary packages or install if not already installed
if (!require(knitr)) {
    install.packages("knitr")
    library(knitr)
}
library(kableExtra)
# Create a data frame with the classification report metrics
# metrics <- data.frame(
#   Class = c('0', '1', 'Accuracy', 'Macro Avg', 'Weighted Avg'),
#   Precision = c(0.69, 0.79, NA, 0.74, 0.76),
#   Recall = c(0.49, 0.90, NA, 0.69, 0.76),
#   `F1-Score` = c(0.57, 0.84, 0.76, 0.71, 0.75),
#   Support = c(11812, 24862, 36674, 36674, 36674)
# )

metrics<- read.csv("nn100k.csv")
nn100k<-data.frame(
  Algorithm = "nn100k",
  Model = "Neural Network",
  `Sample Size`= 100000,
  `Number of Variables` = 105,
  `AUC Score` = round(metrics$AUC[1], 3)
)

# Convert numeric values to text to handle NA values
metricsNN <- data.frame(lapply(metrics, function(x) ifelse(is.na(x), "", x)), stringsAsFactors = FALSE)
metricsNN[2:7]<- mutate_all(metricsNN[2:7], function(x) as.numeric(as.character(x)))
metricsNN <- data.frame(lapply(metricsNN, function(x) {
  if(is.numeric(x)) round(x, 3) else x
}))

# Adjust column names for the table
colnames(metricsNN)[1] <- ""

apa_table(
  metricsNN
  , caption = "Neural Network Predictive Metrics"
  , note = "1= turnover intention, 0= no turnover intention."
  #, align = c("m{2cm}", "m{12cm}")
  #, longtable = TRUE
  , landscape = FALSE
  , escape = FALSE
)
# Use kable to create a nicer table
# kable(metrics, caption = "Neural Network Predictive Metrics", 
#       col.names = c('Class', 'Precision', 'Recall', 'F1-Score', 'Support'), 
#       align = 'c') %>%
#   kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), 
#                 full_width = F, font_size = 12)


```



```{r svm100k, message=FALSE, warning=FALSE}

# Load necessary packages or install if not already installed
if (!require(knitr)) {
    install.packages("knitr")
    library(knitr)
}
library(kableExtra)
# Create a data frame with the classification report metrics
# metrics <- data.frame(
#   Class = c('0', '1', 'Accuracy', 'Macro Avg', 'Weighted Avg'),
#   Precision = c(0.71, 0.77, NA, 0.74, 0.75),
#   Recall = c(0.44, 0.92, NA, 0.68, 0.76),
#   `F1-Score` = c(0.54, 0.84, 0.76, 0.69, 0.74),
#   Support = c(11812, 24862, 36674, 36674, 36674)
# )

metrics<- read.csv("svm100k.csv")
svm100k<-data.frame(
  Algorithm = "svm100k",
  Model = "Support Vector Machines",
  `Sample Size`= 100000,
  `Number of Variables` = 105,
  `AUC Score` = round(metrics$AUC[1], 3)
)

# Convert numeric values to text to handle NA values
metricsSVM <- data.frame(lapply(metrics, function(x) ifelse(is.na(x), "", x)), stringsAsFactors = FALSE)
metricsSVM[2:7]<- mutate_all(metricsSVM[2:7], function(x) as.numeric(as.character(x)))
metricsSVM <- data.frame(lapply(metricsSVM, function(x) {
  if(is.numeric(x)) round(x, 3) else x
}))

# Adjust column names for the table
colnames(metricsSVM)[1] <- ""

apa_table(
  metricsSVM
  , caption = "SVM Predictive Metrics"
  , note = "1= turnover intention, 0= no turnover intention."
  #, align = c("m{2cm}", "m{12cm}")
  #, longtable = TRUE
  , landscape = FALSE
  , escape = FALSE
)

# Use kable to create a nicer table
# kable(metrics, caption = "SVM Predictive Metrics", 
#       col.names = c('Class', 'Precision', 'Recall', 'F1-Score', 'Support'), 
#       align = 'c') %>%
#   kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), 
#                 full_width = F, font_size = 12)


```



```{r rf100k, message=FALSE, warning=FALSE}

# Load necessary packages or install if not already installed
if (!require(knitr)) {
    install.packages("knitr")
    library(knitr)
}
library(kableExtra)
# Create a data frame with the classification report metrics
# metrics <- data.frame(
#   Class = c('0', '1', 'Accuracy', 'Macro Avg', 'Weighted Avg'),
#   Precision = c(0.70, 0.77, NA, 0.73, 0.75),
#   Recall = c(0.43, 0.91, NA, 0.67, 0.76),
#   `F1-Score` = c(0.53, 0.83, 0.76, 0.68, 0.74),
#   Support = c(11812, 24862, 36674, 36674, 36674)
# )

metrics<- read.csv("rf100k.csv")
rf100k<-data.frame(
  Algorithm = "rf100k",
  Model = "Random Forest",
  `Sample Size`= 100000,
  `Number of Variables` = 105,
  `AUC Score` = round(metrics$AUC[1], 3)
)

# Convert numeric values to text to handle NA values
metricsRF <- data.frame(lapply(metrics, function(x) ifelse(is.na(x), "", x)), stringsAsFactors = FALSE)
metricsRF[2:7]<- mutate_all(metricsRF[2:7], function(x) as.numeric(as.character(x)))
metricsRF <- data.frame(lapply(metricsRF, function(x) {
  if(is.numeric(x)) round(x, 3) else x
}))

# Adjust column names for the table
colnames(metricsRF)[1] <- ""

apa_table(
  metricsRF
  , caption = "Random Forest Predictive Metrics"
  , note = "1= turnover intention, 0= no turnover intention."
  #, align = c("m{2cm}", "m{12cm}")
  #, longtable = TRUE
  , landscape = FALSE
  , escape = FALSE
)
# Use kable to create a nicer table
# kable(metrics, caption = "Random Forest Predictive Metrics", 
#       col.names = c('Class', 'Precision', 'Recall', 'F1-Score', 'Support'), 
#       align = 'c') %>%
#   kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), 
#                 full_width = F, font_size = 12)


```

For all of these analyses, the dataset was split into a training dataset of 80,000 and a testing dataset of 20,000. All predictive performance metrics were obtained through cross-validation on the testing dataset. A logistic regression analysis was conducted to predict turnover intention based on the set of 104 FEVS predictors. Overall accuracy across categories was `r metricsLOGI$Accuracy[3]`, as can be seen in table \@ref(tab:logitable100k). The weighted average precision was `r metricsLOGI$Precision[3]`, with a recall of `r metricsLOGI$Recall[3]` and an F1 score of `r metricsLOGI$F1.score[3]`, suggesting a moderate level of prediction consistency across categories. 
The performance of a xgboosting model across categories was `r metricsXGB$Accuracy[3]`, as can be seen in table \@ref(tab:xgbtable100k). The weighted average precision was `r metricsXGB$Precision[4]`, with a recall of `r metricsXGB$Recall[4]` and an F1 score of `r metricsXGB$F1.score[4]`, suggesting moderate levels of predictive accuracy. 
The performance of a neural network model across categories was `r metricsNN$F1.score[3]`, as can be seen in table \@ref(tab:nn100k). The weighted average precision was `r metricsNN$Precision[4]`, with a recall of `r metricsNN$Recall[4]` and an F1 score of `r metricsNN$F1.score[4]`, suggesting moderate levels of predictive accuracy. 
The performance of a SVM model across categories was `r metricsSVM$F1.score[3]`, as can be seen in table \@ref(tab:svm100k). The weighted average precision was `r metricsSVM$Precision[4]`, with a recall of `r metricsSVM$Recall[4]` and an F1 score of `r metricsSVM$F1.score[4]`, suggesting moderate levels of predictive accuracy.
The performance of a random forest model across categories was `r metricsRF$F1.score[3]`, as can be seen in table \@ref(tab:rf100k). The weighted average precision was `r metricsRF$Precision[4]`, with a recall of `r metricsRF$Recall[4]` and an F1 score of `r metricsRF$F1.score[4]`, suggesting moderate levels of predictive accuracy. 
