{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f54435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e851580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DLEAVING</th>\n",
       "      <th>workXP</th>\n",
       "      <th>workUnit</th>\n",
       "      <th>workOffice</th>\n",
       "      <th>workOrg</th>\n",
       "      <th>workSuper</th>\n",
       "      <th>leadership</th>\n",
       "      <th>workSat</th>\n",
       "      <th>DEI</th>\n",
       "      <th>employeeXP</th>\n",
       "      <th>flexibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46608</th>\n",
       "      <td>1</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11518</th>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>3.357143</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80411</th>\n",
       "      <td>0</td>\n",
       "      <td>3.615385</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23295</th>\n",
       "      <td>0</td>\n",
       "      <td>4.230769</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40034</th>\n",
       "      <td>1</td>\n",
       "      <td>3.461538</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46597</th>\n",
       "      <td>1</td>\n",
       "      <td>4.538462</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.357143</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91152</th>\n",
       "      <td>1</td>\n",
       "      <td>3.692308</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>3.214286</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98192</th>\n",
       "      <td>1</td>\n",
       "      <td>4.076923</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84617</th>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41758</th>\n",
       "      <td>0</td>\n",
       "      <td>3.769231</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>3.357143</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       DLEAVING    workXP  workUnit  workOffice  workOrg  workSuper  \\\n",
       "46608         1  5.000000       4.8         5.0      4.9        5.0   \n",
       "11518         1  4.000000       3.9         3.7      3.7        4.6   \n",
       "80411         0  3.615385       4.4         3.8      3.8        4.8   \n",
       "23295         0  4.230769       4.5         3.6      3.8        4.5   \n",
       "40034         1  3.461538       3.5         3.5      4.1        4.3   \n",
       "...         ...       ...       ...         ...      ...        ...   \n",
       "46597         1  4.538462       4.4         4.4      4.2        5.0   \n",
       "91152         1  3.692308       4.2         4.0      3.6        3.8   \n",
       "98192         1  4.076923       4.0         3.6      4.1        3.8   \n",
       "84617         1  4.000000       4.2         4.0      4.3        4.7   \n",
       "41758         0  3.769231       4.2         3.4      3.5        4.8   \n",
       "\n",
       "       leadership   workSat       DEI  employeeXP  flexibility  \n",
       "46608         4.9  5.000000  5.000000         5.0          3.6  \n",
       "11518         4.1  4.166667  3.357143         4.6          3.1  \n",
       "80411         3.4  4.000000  4.000000         3.6          3.7  \n",
       "23295         4.1  3.666667  4.000000         3.2          3.2  \n",
       "40034         3.6  4.000000  3.928571         4.2          3.0  \n",
       "...           ...       ...       ...         ...          ...  \n",
       "46597         4.6  4.666667  4.357143         4.4          3.1  \n",
       "91152         3.6  3.166667  3.214286         3.2          2.8  \n",
       "98192         4.0  4.000000  4.000000         3.8          2.8  \n",
       "84617         4.2  3.833333  4.000000         4.0          2.9  \n",
       "41758         2.6  3.166667  3.357143         3.2          3.0  \n",
       "\n",
       "[1000 rows x 11 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data_cleaned.csv\")\n",
    "data = data.sample(n=1000, random_state=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b280160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y=data['DLEAVING']\n",
    "X=data.iloc[:, -10:]\n",
    "X_train, X_test, y_train, y_test= train_test_split(\n",
    "                                                X, y,\n",
    "                                                test_size=0.33,\n",
    "                                                random_state=53)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d019597f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.45      0.55       110\n",
      "           1       0.77      0.90      0.83       220\n",
      "\n",
      "    accuracy                           0.75       330\n",
      "   macro avg       0.74      0.68      0.69       330\n",
      "weighted avg       0.75      0.75      0.74       330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "reg = LogisticRegression().fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "deb89002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.44      0.54       110\n",
      "           1       0.76      0.91      0.83       220\n",
      "\n",
      "    accuracy                           0.75       330\n",
      "   macro avg       0.74      0.68      0.69       330\n",
      "weighted avg       0.75      0.75      0.74       330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "\n",
    "param_grid = {'max_depth':range(1, 5),\n",
    "                'learning_rate':(0.005, 0.05, 0.5)}\n",
    " \n",
    "grid = GridSearchCV(xgb.XGBClassifier(random_state=0), \n",
    "                    param_grid=param_grid, cv=10, verbose=1, scoring='accuracy')\n",
    "    \n",
    "grid.fit(X_train, y_train)\n",
    "pred1 = grid.predict(X_test)\n",
    "print (classification_report(y_test,pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "796361e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diego\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5232 - loss: 0.9612\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6851 - loss: 0.5979 \n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6826 - loss: 0.5927 \n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6924 - loss: 0.5823 \n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7083 - loss: 0.5575 \n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7172 - loss: 0.5447 \n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7248 - loss: 0.5658 \n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7215 - loss: 0.5474 \n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7118 - loss: 0.5773 \n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7218 - loss: 0.5604 \n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.46      0.55       110\n",
      "           1       0.77      0.88      0.82       220\n",
      "\n",
      "    accuracy                           0.74       330\n",
      "   macro avg       0.71      0.67      0.68       330\n",
      "weighted avg       0.73      0.74      0.73       330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Define a simple neural network model for binary classification\n",
    "model = Sequential([\n",
    "    Dense(128, input_shape=(X_train.shape[1],), activation='relu'),  # Input layer with ReLU activation\n",
    "    Dense(64, activation='relu'),  # Hidden layer with ReLU activation\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model with optimizer, loss function, and metrics for binary classification\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model on the training dataset\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "# Make predictions on the testing dataset\n",
    "pred_probs = model.predict(X_test)\n",
    "pred_nn = np.round(pred_probs).astype(int)  # Convert probabilities to binary class labels\n",
    "\n",
    "# Generate a classification report to evaluate the model\n",
    "print(classification_report(y_test, pred_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72c6578b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "[CV 1/10] END clf__C=0.01, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.001;, score=0.716 total time=   0.0s\n",
      "[CV 2/10] END clf__C=0.01, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.001;, score=0.687 total time=   0.0s\n",
      "[CV 3/10] END clf__C=0.01, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.001;, score=0.731 total time=   0.0s\n",
      "[CV 4/10] END clf__C=0.01, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.001;, score=0.716 total time=   0.0s\n",
      "[CV 5/10] END clf__C=0.01, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.001;, score=0.746 total time=   0.0s\n",
      "[CV 6/10] END clf__C=0.01, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.001;, score=0.761 total time=   0.0s\n",
      "[CV 7/10] END clf__C=0.01, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.001;, score=0.657 total time=   0.0s\n",
      "[CV 8/10] END clf__C=0.01, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.001;, score=0.776 total time=   0.0s\n",
      "[CV 9/10] END clf__C=0.01, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.001;, score=0.731 total time=   0.0s\n",
      "[CV 10/10] END clf__C=0.01, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.001;, score=0.836 total time=   0.0s\n",
      "[CV 1/10] END clf__C=100, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.01;, score=0.701 total time=   0.0s\n",
      "[CV 2/10] END clf__C=100, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.01;, score=0.716 total time=   0.0s\n",
      "[CV 3/10] END clf__C=100, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.01;, score=0.716 total time=   0.0s\n",
      "[CV 4/10] END clf__C=100, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.01;, score=0.687 total time=   0.0s\n",
      "[CV 5/10] END clf__C=100, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.01;, score=0.806 total time=   0.0s\n",
      "[CV 6/10] END clf__C=100, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.01;, score=0.776 total time=   0.0s\n",
      "[CV 7/10] END clf__C=100, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.01;, score=0.672 total time=   0.0s\n",
      "[CV 8/10] END clf__C=100, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.01;, score=0.791 total time=   0.0s\n",
      "[CV 9/10] END clf__C=100, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.01;, score=0.716 total time=   0.0s\n",
      "[CV 10/10] END clf__C=100, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.01;, score=0.806 total time=   0.0s\n",
      "[CV 1/10] END clf__C=0.01, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.01;, score=0.746 total time=   0.0s\n",
      "[CV 2/10] END clf__C=0.01, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.01;, score=0.687 total time=   0.0s\n",
      "[CV 3/10] END clf__C=0.01, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.01;, score=0.687 total time=   0.0s\n",
      "[CV 4/10] END clf__C=0.01, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.01;, score=0.806 total time=   0.0s\n",
      "[CV 5/10] END clf__C=0.01, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.01;, score=0.731 total time=   0.0s\n",
      "[CV 6/10] END clf__C=0.01, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.01;, score=0.731 total time=   0.0s\n",
      "[CV 7/10] END clf__C=0.01, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.01;, score=0.716 total time=   0.0s\n",
      "[CV 8/10] END clf__C=0.01, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.01;, score=0.731 total time=   0.0s\n",
      "[CV 9/10] END clf__C=0.01, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.01;, score=0.701 total time=   0.0s\n",
      "[CV 10/10] END clf__C=0.01, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.01;, score=0.776 total time=   0.0s\n",
      "[CV 1/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.716 total time=   0.0s\n",
      "[CV 2/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.731 total time=   0.0s\n",
      "[CV 3/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.701 total time=   0.0s\n",
      "[CV 4/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.672 total time=   0.0s\n",
      "[CV 5/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.806 total time=   0.0s\n",
      "[CV 6/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.806 total time=   0.0s\n",
      "[CV 7/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.657 total time=   0.0s\n",
      "[CV 8/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.791 total time=   0.0s\n",
      "[CV 9/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.716 total time=   0.0s\n",
      "[CV 10/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.791 total time=   0.0s\n",
      "[CV 1/10] END clf__C=0.01, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.001;, score=0.716 total time=   0.0s\n",
      "[CV 2/10] END clf__C=0.01, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.001;, score=0.687 total time=   0.0s\n",
      "[CV 3/10] END clf__C=0.01, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.001;, score=0.731 total time=   0.0s\n",
      "[CV 4/10] END clf__C=0.01, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.001;, score=0.716 total time=   0.0s\n",
      "[CV 5/10] END clf__C=0.01, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.001;, score=0.746 total time=   0.0s\n",
      "[CV 6/10] END clf__C=0.01, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.001;, score=0.761 total time=   0.0s\n",
      "[CV 7/10] END clf__C=0.01, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.001;, score=0.657 total time=   0.0s\n",
      "[CV 8/10] END clf__C=0.01, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.001;, score=0.776 total time=   0.0s\n",
      "[CV 9/10] END clf__C=0.01, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.001;, score=0.731 total time=   0.0s\n",
      "[CV 10/10] END clf__C=0.01, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.001;, score=0.836 total time=   0.0s\n",
      "[CV 1/10] END clf__C=0.1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.01;, score=0.701 total time=   0.0s\n",
      "[CV 2/10] END clf__C=0.1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.01;, score=0.716 total time=   0.0s\n",
      "[CV 3/10] END clf__C=0.1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.01;, score=0.716 total time=   0.0s\n",
      "[CV 4/10] END clf__C=0.1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.01;, score=0.672 total time=   0.0s\n",
      "[CV 5/10] END clf__C=0.1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.01;, score=0.806 total time=   0.0s\n",
      "[CV 6/10] END clf__C=0.1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.01;, score=0.791 total time=   0.0s\n",
      "[CV 7/10] END clf__C=0.1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.01;, score=0.672 total time=   0.0s\n",
      "[CV 8/10] END clf__C=0.1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.01;, score=0.806 total time=   0.0s\n",
      "[CV 9/10] END clf__C=0.1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.01;, score=0.716 total time=   0.0s\n",
      "[CV 10/10] END clf__C=0.1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.01;, score=0.806 total time=   0.0s\n",
      "[CV 1/10] END clf__C=1, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.01;, score=0.716 total time=   0.0s\n",
      "[CV 2/10] END clf__C=1, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.01;, score=0.731 total time=   0.0s\n",
      "[CV 3/10] END clf__C=1, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.01;, score=0.701 total time=   0.0s\n",
      "[CV 4/10] END clf__C=1, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.01;, score=0.672 total time=   0.0s\n",
      "[CV 5/10] END clf__C=1, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.01;, score=0.806 total time=   0.0s\n",
      "[CV 6/10] END clf__C=1, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.01;, score=0.806 total time=   0.0s\n",
      "[CV 7/10] END clf__C=1, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.01;, score=0.657 total time=   0.0s\n",
      "[CV 8/10] END clf__C=1, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.01;, score=0.806 total time=   0.0s\n",
      "[CV 9/10] END clf__C=1, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.01;, score=0.716 total time=   0.0s\n",
      "[CV 10/10] END clf__C=1, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.01;, score=0.791 total time=   0.0s\n",
      "[CV 1/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.01;, score=0.701 total time=   0.0s\n",
      "[CV 2/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.01;, score=0.716 total time=   0.0s\n",
      "[CV 3/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.01;, score=0.716 total time=   0.0s\n",
      "[CV 4/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.01;, score=0.672 total time=   0.0s\n",
      "[CV 5/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.01;, score=0.821 total time=   0.0s\n",
      "[CV 6/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.01;, score=0.806 total time=   0.0s\n",
      "[CV 7/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.01;, score=0.672 total time=   0.0s\n",
      "[CV 8/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.01;, score=0.806 total time=   0.0s\n",
      "[CV 9/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.01;, score=0.716 total time=   0.0s\n",
      "[CV 10/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.01;, score=0.806 total time=   0.0s\n",
      "[CV 1/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.716 total time=   0.0s\n",
      "[CV 2/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.731 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.701 total time=   0.0s\n",
      "[CV 4/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.672 total time=   0.0s\n",
      "[CV 5/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.821 total time=   0.0s\n",
      "[CV 6/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.806 total time=   0.0s\n",
      "[CV 7/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.672 total time=   0.0s\n",
      "[CV 8/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.791 total time=   0.0s\n",
      "[CV 9/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.716 total time=   0.0s\n",
      "[CV 10/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.791 total time=   0.0s\n",
      "[CV 1/10] END clf__C=0.01, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.0001;, score=0.716 total time=   0.0s\n",
      "[CV 2/10] END clf__C=0.01, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.0001;, score=0.687 total time=   0.0s\n",
      "[CV 3/10] END clf__C=0.01, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.0001;, score=0.731 total time=   0.0s\n",
      "[CV 4/10] END clf__C=0.01, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.0001;, score=0.731 total time=   0.0s\n",
      "[CV 5/10] END clf__C=0.01, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.0001;, score=0.746 total time=   0.0s\n",
      "[CV 6/10] END clf__C=0.01, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.0001;, score=0.761 total time=   0.0s\n",
      "[CV 7/10] END clf__C=0.01, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.0001;, score=0.657 total time=   0.0s\n",
      "[CV 8/10] END clf__C=0.01, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.0001;, score=0.776 total time=   0.0s\n",
      "[CV 9/10] END clf__C=0.01, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.0001;, score=0.731 total time=   0.0s\n",
      "[CV 10/10] END clf__C=0.01, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.0001;, score=0.836 total time=   0.0s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.45      0.56       110\n",
      "           1       0.77      0.91      0.83       220\n",
      "\n",
      "    accuracy                           0.76       330\n",
      "   macro avg       0.74      0.68      0.69       330\n",
      "weighted avg       0.75      0.76      0.74       330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "pipeline = Pipeline([\n",
    "    ('clf', LinearSVC(dual=False))  # 'clf' is the name we give to the LinearSVC step\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Define a very simple parameter grid, could be expanded based on need\n",
    "param_grid = {\n",
    "    'clf__penalty': ['l1', 'l2'],\n",
    "    'clf__loss': ['squared_hinge'],\n",
    "    'clf__tol': [1e-4, 1e-3, 1e-2],\n",
    "    'clf__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'clf__max_iter': [1000, 2000, 3000],\n",
    "    'clf__intercept_scaling': [1, 10, 100]\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize GridSearchCV with the SVC estimator and the simple param grid\n",
    "grid = RandomizedSearchCV(pipeline, param_grid, verbose=3, cv=10)\n",
    "\n",
    "# Train the model on the training dataset\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing dataset using the best model found\n",
    "pred_svm = grid.predict(X_test)\n",
    "\n",
    "# Generate a classification report to evaluate the model\n",
    "print(classification_report(y_test, pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e7f890e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.43      0.53       110\n",
      "           1       0.76      0.90      0.83       220\n",
      "\n",
      "    accuracy                           0.75       330\n",
      "   macro avg       0.73      0.67      0.68       330\n",
      "weighted avg       0.74      0.75      0.73       330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Adjusting the parameter grid for RandomForestClassifier\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 200],  # Number of trees in the forest\n",
    "    'max_depth': range(1, 5)  # Maximum depth of the tree\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(RandomForestClassifier(random_state=0),\n",
    "                    param_grid=param_grid, cv=10, verbose=1, scoring='accuracy')\n",
    "\n",
    "# Fit to the training data\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "pred1 = grid.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, pred1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
