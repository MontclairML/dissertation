{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4d3ad48",
   "metadata": {},
   "source": [
    "# Study 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81d76c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2280f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TI</th>\n",
       "      <th>EES</th>\n",
       "      <th>JIMS</th>\n",
       "      <th>SPOS</th>\n",
       "      <th>BFI</th>\n",
       "      <th>ACS</th>\n",
       "      <th>NCS</th>\n",
       "      <th>MOAQ</th>\n",
       "      <th>GSOI</th>\n",
       "      <th>BIO1</th>\n",
       "      <th>...</th>\n",
       "      <th>BIO4</th>\n",
       "      <th>BIO5</th>\n",
       "      <th>BIO6</th>\n",
       "      <th>BIO7</th>\n",
       "      <th>BIO8</th>\n",
       "      <th>BIO9_1</th>\n",
       "      <th>BIO10</th>\n",
       "      <th>BIO11</th>\n",
       "      <th>BIO12</th>\n",
       "      <th>BIO13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3.11</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>2.888889</td>\n",
       "      <td>1.250</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.53</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>3.555556</td>\n",
       "      <td>3.500</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>3.125</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.93</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>3.222222</td>\n",
       "      <td>2.750</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.99</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>2.888889</td>\n",
       "      <td>2.250</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3.74</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.4</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.555556</td>\n",
       "      <td>2.500</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>1.875</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4.00</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.625</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3.06</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>241 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TI       EES  JIMS      SPOS       BFI       ACS    NCS      MOAQ  GSOI  \\\n",
       "0     0  3.666667   3.1  2.500000  2.666667  3.000000  3.000  3.000000     4   \n",
       "1     0  4.000000   1.8  5.000000  4.833333  2.888889  1.250  5.000000     1   \n",
       "2     0  3.666667   2.9  4.333333  3.833333  3.555556  3.500  5.000000     4   \n",
       "3     1  3.666667   3.1  3.166667  3.166667  2.555556  3.125  3.000000     3   \n",
       "4     0  3.666667   3.3  4.166667  4.166667  2.777778  3.000  3.666667     5   \n",
       "..   ..       ...   ...       ...       ...       ...    ...       ...   ...   \n",
       "236   0  2.000000   2.3  1.333333  3.833333  3.222222  2.750  4.000000     3   \n",
       "237   0  4.000000   2.9  3.833333  3.833333  2.888889  2.250  4.000000     3   \n",
       "238   0  4.000000   2.4  5.000000  3.000000  3.555556  2.500  4.666667     7   \n",
       "239   0  3.000000   2.1  2.333333  1.833333  2.777778  1.875  3.666667     4   \n",
       "240   1  3.000000   1.8  3.333333  2.666667  2.333333  1.625  3.666667     1   \n",
       "\n",
       "     BIO1  ...  BIO4  BIO5  BIO6  BIO7  BIO8  BIO9_1  BIO10  BIO11  BIO12  \\\n",
       "0       4  ...     2     3     3     2     3    3.11      5      3      3   \n",
       "1       5  ...     2     5     1     2     1    3.53      5      5      5   \n",
       "2       3  ...     2     3     2     1     3    3.00      3      5      5   \n",
       "3       3  ...     2     4     2     3     3    2.50      3      2      3   \n",
       "4       1  ...     1     3     1     1     1    3.93      5      3      3   \n",
       "..    ...  ...   ...   ...   ...   ...   ...     ...    ...    ...    ...   \n",
       "236     1  ...     2     4     1     1     1    2.99      3      3      1   \n",
       "237     1  ...     2     5     2     4     5    3.74      6      3      3   \n",
       "238     3  ...     3     5     2     1     2    3.00      3      3      3   \n",
       "239     4  ...     2     5     2     5     1    4.00      8      3      2   \n",
       "240     4  ...     5     4     2     3     2    3.06      5      2      2   \n",
       "\n",
       "     BIO13  \n",
       "0        3  \n",
       "1        5  \n",
       "2        5  \n",
       "3        5  \n",
       "4        3  \n",
       "..     ...  \n",
       "236      5  \n",
       "237      5  \n",
       "238      5  \n",
       "239      5  \n",
       "240      1  \n",
       "\n",
       "[241 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data_study2.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35205721",
   "metadata": {},
   "source": [
    "# Baseline models: biodata only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d83669f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y=data['MOAQ']\n",
    "X=data.iloc[:,9:22]\n",
    "X_train, X_test, y_train, y_test= train_test_split(\n",
    "                                                X, y,\n",
    "                                                test_size=0.2,\n",
    "                                                random_state=53)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbe72f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6613507621106413\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "#X_train = np.array(X_train).reshape(-1,1)\n",
    "#y_train = np.array(y_train).reshape(-1,1)\n",
    "\n",
    "#X_test = np.array(X_test).reshape(-1,1)\n",
    "#y_test = np.array(y_test).reshape(-1,1)\n",
    "# Initialize and fit the linear regression model\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_lin = reg.predict(X_test)\n",
    "\n",
    "# Computing RMSE\n",
    "rmse_reg = np.sqrt(mean_squared_error(y_test, y_pred_lin))\n",
    "print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11984073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
      "RMSE: 0.5908881776087875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Define the parameter grid for XGBoost\n",
    "param_grid = {\n",
    "    'max_depth': range(1, 5),\n",
    "    'learning_rate': [0.005, 0.05, 0.5]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with XGBoost Regressor\n",
    "grid = GridSearchCV(xgb.XGBRegressor(random_state=0),\n",
    "                    param_grid=param_grid, cv=10, verbose=1, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Train the model on the training dataset\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing dataset\n",
    "y_pred_xgb = grid.predict(X_test)\n",
    "\n",
    "# Computing RMSE\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
    "print(f\"RMSE: {rmse_xgb}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f2a446c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diego\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 8.3465 - mean_squared_error: 8.3465    \n",
      "Epoch 2/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6665 - mean_squared_error: 1.6665 \n",
      "Epoch 3/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4349 - mean_squared_error: 1.4349 \n",
      "Epoch 4/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8388 - mean_squared_error: 0.8388 \n",
      "Epoch 5/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9355 - mean_squared_error: 0.9355 \n",
      "Epoch 6/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6741 - mean_squared_error: 0.6741 \n",
      "Epoch 7/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7093 - mean_squared_error: 0.7093 \n",
      "Epoch 8/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5056 - mean_squared_error: 0.5056 \n",
      "Epoch 9/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6098 - mean_squared_error: 0.6098 \n",
      "Epoch 10/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4908 - mean_squared_error: 0.4908 \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "RMSE: 0.5689883491181758\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Define a simple neural network model for regression\n",
    "model = Sequential([\n",
    "    Dense(128, input_shape=(X_train.shape[1],), activation='relu'),  # Input layer with ReLU activation\n",
    "    Dense(64, activation='relu'),  # Hidden layer with ReLU activation\n",
    "    Dense(1)  # Output layer for regression (no activation function)\n",
    "])\n",
    "\n",
    "# Compile the model with optimizer and loss function suitable for regression\n",
    "model.compile(optimizer='adam', \n",
    "              loss='mean_squared_error',  # Change the loss function to MSE for regression\n",
    "              metrics=['mean_squared_error'])  # Change the metric to MSE\n",
    "\n",
    "# Train the model on the training dataset\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "# Make predictions on the testing dataset\n",
    "y_pred_nn = model.predict(X_test)\n",
    "\n",
    "# Computing RMSE\n",
    "rmse_nn = np.sqrt(mean_squared_error(y_test, y_pred_nn))\n",
    "print(f\"RMSE: {rmse_nn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2adf2377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "RMSE: 0.5452796386682599\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Define the pipeline with SVR instead of LinearSVC\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # It's common to scale inputs for SVM\n",
    "    ('svr', SVR())  # Use SVR for regression\n",
    "])\n",
    "\n",
    "# Define a parameter grid adapted for SVR\n",
    "param_grid = {\n",
    "    'svr__kernel': ['linear', 'poly', 'rbf'],  # SVR kernels\n",
    "    'svr__C': [0.01, 0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'svr__epsilon': [0.001, 0.01, 0.1, 1]  # Epsilon in the epsilon-SVR model\n",
    "}\n",
    "\n",
    "# Initialize RandomizedSearchCV with the SVR estimator and the parameter grid\n",
    "grid = RandomizedSearchCV(pipeline, param_grid, verbose=3, cv=10, n_jobs=-1)\n",
    "\n",
    "# Train the model on the training dataset\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing dataset using the best model found\n",
    "pred_svr = grid.predict(X_test)\n",
    "\n",
    "# Computing RMSE\n",
    "rmse_svr = np.sqrt(mean_squared_error(y_test, pred_svr))\n",
    "print(f\"RMSE: {rmse_svr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5924ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "RMSE: 0.5785559877305311\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Adjusting the parameter grid for RandomForestRegressor\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 200],  # Number of trees in the forest\n",
    "    'max_depth': range(1, 5)  # Maximum depth of the tree\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with the RandomForestRegressor and the parameter grid\n",
    "grid = GridSearchCV(RandomForestRegressor(random_state=0),\n",
    "                    param_grid=param_grid, cv=10, verbose=1, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit to the training data\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing dataset\n",
    "y_pred_rf = grid.predict(X_test)\n",
    "\n",
    "# Computing RMSE\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "print(f\"RMSE: {rmse_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24f325e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataset with the model names and their corresponding AUC scores\n",
    "data = {\n",
    "    \"Model\": [\"Linear Regression\", \"XGBoost\", \"Neural Network\", \"SVM\", \"Random Forest\"],\n",
    "    \"RMSE\": [rmse_reg, rmse_xgb, rmse_nn, rmse_svr, rmse_rf]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Writing the dataset to a .csv file\n",
    "csv_file_path = \"base_model_rmse_scores.csv\"  # Specify your desired path and filename\n",
    "df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda0a215",
   "metadata": {},
   "source": [
    "# WRC Model: work-related psychological constructs only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06d033fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TI</th>\n",
       "      <th>EES</th>\n",
       "      <th>JIMS</th>\n",
       "      <th>SPOS</th>\n",
       "      <th>BFI</th>\n",
       "      <th>ACS</th>\n",
       "      <th>NCS</th>\n",
       "      <th>MOAQ</th>\n",
       "      <th>GSOI</th>\n",
       "      <th>BIO1</th>\n",
       "      <th>...</th>\n",
       "      <th>BIO4</th>\n",
       "      <th>BIO5</th>\n",
       "      <th>BIO6</th>\n",
       "      <th>BIO7</th>\n",
       "      <th>BIO8</th>\n",
       "      <th>BIO9_1</th>\n",
       "      <th>BIO10</th>\n",
       "      <th>BIO11</th>\n",
       "      <th>BIO12</th>\n",
       "      <th>BIO13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3.11</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>2.888889</td>\n",
       "      <td>1.250</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.53</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>3.555556</td>\n",
       "      <td>3.500</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>3.125</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.93</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>3.222222</td>\n",
       "      <td>2.750</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.99</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>2.888889</td>\n",
       "      <td>2.250</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3.74</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.4</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.555556</td>\n",
       "      <td>2.500</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>1.875</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4.00</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.625</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3.06</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>241 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TI       EES  JIMS      SPOS       BFI       ACS    NCS      MOAQ  GSOI  \\\n",
       "0     0  3.666667   3.1  2.500000  2.666667  3.000000  3.000  3.000000     4   \n",
       "1     0  4.000000   1.8  5.000000  4.833333  2.888889  1.250  5.000000     1   \n",
       "2     0  3.666667   2.9  4.333333  3.833333  3.555556  3.500  5.000000     4   \n",
       "3     1  3.666667   3.1  3.166667  3.166667  2.555556  3.125  3.000000     3   \n",
       "4     0  3.666667   3.3  4.166667  4.166667  2.777778  3.000  3.666667     5   \n",
       "..   ..       ...   ...       ...       ...       ...    ...       ...   ...   \n",
       "236   0  2.000000   2.3  1.333333  3.833333  3.222222  2.750  4.000000     3   \n",
       "237   0  4.000000   2.9  3.833333  3.833333  2.888889  2.250  4.000000     3   \n",
       "238   0  4.000000   2.4  5.000000  3.000000  3.555556  2.500  4.666667     7   \n",
       "239   0  3.000000   2.1  2.333333  1.833333  2.777778  1.875  3.666667     4   \n",
       "240   1  3.000000   1.8  3.333333  2.666667  2.333333  1.625  3.666667     1   \n",
       "\n",
       "     BIO1  ...  BIO4  BIO5  BIO6  BIO7  BIO8  BIO9_1  BIO10  BIO11  BIO12  \\\n",
       "0       4  ...     2     3     3     2     3    3.11      5      3      3   \n",
       "1       5  ...     2     5     1     2     1    3.53      5      5      5   \n",
       "2       3  ...     2     3     2     1     3    3.00      3      5      5   \n",
       "3       3  ...     2     4     2     3     3    2.50      3      2      3   \n",
       "4       1  ...     1     3     1     1     1    3.93      5      3      3   \n",
       "..    ...  ...   ...   ...   ...   ...   ...     ...    ...    ...    ...   \n",
       "236     1  ...     2     4     1     1     1    2.99      3      3      1   \n",
       "237     1  ...     2     5     2     4     5    3.74      6      3      3   \n",
       "238     3  ...     3     5     2     1     2    3.00      3      3      3   \n",
       "239     4  ...     2     5     2     5     1    4.00      8      3      2   \n",
       "240     4  ...     5     4     2     3     2    3.06      5      2      2   \n",
       "\n",
       "     BIO13  \n",
       "0        3  \n",
       "1        5  \n",
       "2        5  \n",
       "3        5  \n",
       "4        3  \n",
       "..     ...  \n",
       "236      5  \n",
       "237      5  \n",
       "238      5  \n",
       "239      5  \n",
       "240      1  \n",
       "\n",
       "[241 rows x 22 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data_study2.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb64bf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y=data['MOAQ']\n",
    "X=data[['EES', 'JIMS', 'SPOS', 'BFI', 'ACS', 'NCS', 'MOAQ', 'GSOI']]\n",
    "X_train, X_test, y_train, y_test= train_test_split(\n",
    "                                                X, y,\n",
    "                                                test_size=0.2,\n",
    "                                                random_state=53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af911175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6613507621106413\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "#X_train = np.array(X_train).reshape(-1,1)\n",
    "#y_train = np.array(y_train).reshape(-1,1)\n",
    "\n",
    "#X_test = np.array(X_test).reshape(-1,1)\n",
    "#y_test = np.array(y_test).reshape(-1,1)\n",
    "# Initialize and fit the linear regression model\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_lin = reg.predict(X_test)\n",
    "\n",
    "# Computing RMSE\n",
    "rmse_reg = np.sqrt(mean_squared_error(y_test, y_pred_lin))\n",
    "print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e74c6dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
      "RMSE: 0.005638880915754558\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Define the parameter grid for XGBoost\n",
    "param_grid = {\n",
    "    'max_depth': range(1, 5),\n",
    "    'learning_rate': [0.005, 0.05, 0.5]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with XGBoost Regressor\n",
    "grid = GridSearchCV(xgb.XGBRegressor(random_state=0),\n",
    "                    param_grid=param_grid, cv=10, verbose=1, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Train the model on the training dataset\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing dataset\n",
    "y_pred_xgb = grid.predict(X_test)\n",
    "\n",
    "# Computing RMSE\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
    "print(f\"RMSE: {rmse_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7272d3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diego\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6.1668 - mean_squared_error: 6.1668    \n",
      "Epoch 2/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3794 - mean_squared_error: 1.3794 \n",
      "Epoch 3/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7892 - mean_squared_error: 0.7892 \n",
      "Epoch 4/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6156 - mean_squared_error: 0.6156 \n",
      "Epoch 5/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4251 - mean_squared_error: 0.4251 \n",
      "Epoch 6/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3530 - mean_squared_error: 0.3530 \n",
      "Epoch 7/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2299 - mean_squared_error: 0.2299 \n",
      "Epoch 8/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1934 - mean_squared_error: 0.1934 \n",
      "Epoch 9/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1460 - mean_squared_error: 0.1460 \n",
      "Epoch 10/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1053 - mean_squared_error: 0.1053 \n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001CFC39B8FE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/stepWARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001CFC39B8FE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "RMSE: 0.2610337648830696\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Define a simple neural network model for regression\n",
    "model = Sequential([\n",
    "    Dense(128, input_shape=(X_train.shape[1],), activation='relu'),  # Input layer with ReLU activation\n",
    "    Dense(64, activation='relu'),  # Hidden layer with ReLU activation\n",
    "    Dense(1)  # Output layer for regression (no activation function)\n",
    "])\n",
    "\n",
    "# Compile the model with optimizer and loss function suitable for regression\n",
    "model.compile(optimizer='adam', \n",
    "              loss='mean_squared_error',  # Change the loss function to MSE for regression\n",
    "              metrics=['mean_squared_error'])  # Change the metric to MSE\n",
    "\n",
    "# Train the model on the training dataset\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "# Make predictions on the testing dataset\n",
    "y_pred_nn = model.predict(X_test)\n",
    "\n",
    "# Computing RMSE\n",
    "rmse_nn = np.sqrt(mean_squared_error(y_test, y_pred_nn))\n",
    "print(f\"RMSE: {rmse_nn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8b936f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "RMSE: 0.0484159817169608\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Define the pipeline with SVR instead of LinearSVC\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # It's common to scale inputs for SVM\n",
    "    ('svr', SVR())  # Use SVR for regression\n",
    "])\n",
    "\n",
    "# Define a parameter grid adapted for SVR\n",
    "param_grid = {\n",
    "    'svr__kernel': ['linear', 'poly', 'rbf'],  # SVR kernels\n",
    "    'svr__C': [0.01, 0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'svr__epsilon': [0.001, 0.01, 0.1, 1]  # Epsilon in the epsilon-SVR model\n",
    "}\n",
    "\n",
    "# Initialize RandomizedSearchCV with the SVR estimator and the parameter grid\n",
    "grid = RandomizedSearchCV(pipeline, param_grid, verbose=3, cv=10, n_jobs=-1)\n",
    "\n",
    "# Train the model on the training dataset\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing dataset using the best model found\n",
    "pred_svr = grid.predict(X_test)\n",
    "\n",
    "# Computing RMSE\n",
    "rmse_svr = np.sqrt(mean_squared_error(y_test, pred_svr))\n",
    "print(f\"RMSE: {rmse_svr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f8ac342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "RMSE: 0.007493966623847667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Adjusting the parameter grid for RandomForestRegressor\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 200],  # Number of trees in the forest\n",
    "    'max_depth': range(1, 5)  # Maximum depth of the tree\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with the RandomForestRegressor and the parameter grid\n",
    "grid = GridSearchCV(RandomForestRegressor(random_state=0),\n",
    "                    param_grid=param_grid, cv=10, verbose=1, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit to the training data\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing dataset\n",
    "y_pred_rf = grid.predict(X_test)\n",
    "\n",
    "# Computing RMSE\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "print(f\"RMSE: {rmse_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c3dcda5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataset with the model names and their corresponding AUC scores\n",
    "data = {\n",
    "    \"Model\": [\"Logistic Regression\", \"XGBoost\", \"Neural Network\", \"SVM\", \"Random Forest\"],\n",
    "    \"RMSE\": [rmse_reg, rmse_xgb, rmse_nn, rmse_svr, rmse_rf]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Writing the dataset to a .csv file\n",
    "csv_file_path = \"addedWRC_model_rmse_scores.csv\"  # Specify your desired path and filename\n",
    "df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec48ec5e",
   "metadata": {},
   "source": [
    "# All-variables model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fa8f1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TI</th>\n",
       "      <th>EES</th>\n",
       "      <th>JIMS</th>\n",
       "      <th>SPOS</th>\n",
       "      <th>BFI</th>\n",
       "      <th>ACS</th>\n",
       "      <th>NCS</th>\n",
       "      <th>MOAQ</th>\n",
       "      <th>GSOI</th>\n",
       "      <th>BIO1</th>\n",
       "      <th>...</th>\n",
       "      <th>BIO4</th>\n",
       "      <th>BIO5</th>\n",
       "      <th>BIO6</th>\n",
       "      <th>BIO7</th>\n",
       "      <th>BIO8</th>\n",
       "      <th>BIO9_1</th>\n",
       "      <th>BIO10</th>\n",
       "      <th>BIO11</th>\n",
       "      <th>BIO12</th>\n",
       "      <th>BIO13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3.11</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>2.888889</td>\n",
       "      <td>1.250</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.53</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>3.555556</td>\n",
       "      <td>3.500</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>3.125</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.93</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>3.222222</td>\n",
       "      <td>2.750</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.99</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>2.888889</td>\n",
       "      <td>2.250</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3.74</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.4</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.555556</td>\n",
       "      <td>2.500</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>1.875</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4.00</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.625</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3.06</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>241 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TI       EES  JIMS      SPOS       BFI       ACS    NCS      MOAQ  GSOI  \\\n",
       "0     0  3.666667   3.1  2.500000  2.666667  3.000000  3.000  3.000000     4   \n",
       "1     0  4.000000   1.8  5.000000  4.833333  2.888889  1.250  5.000000     1   \n",
       "2     0  3.666667   2.9  4.333333  3.833333  3.555556  3.500  5.000000     4   \n",
       "3     1  3.666667   3.1  3.166667  3.166667  2.555556  3.125  3.000000     3   \n",
       "4     0  3.666667   3.3  4.166667  4.166667  2.777778  3.000  3.666667     5   \n",
       "..   ..       ...   ...       ...       ...       ...    ...       ...   ...   \n",
       "236   0  2.000000   2.3  1.333333  3.833333  3.222222  2.750  4.000000     3   \n",
       "237   0  4.000000   2.9  3.833333  3.833333  2.888889  2.250  4.000000     3   \n",
       "238   0  4.000000   2.4  5.000000  3.000000  3.555556  2.500  4.666667     7   \n",
       "239   0  3.000000   2.1  2.333333  1.833333  2.777778  1.875  3.666667     4   \n",
       "240   1  3.000000   1.8  3.333333  2.666667  2.333333  1.625  3.666667     1   \n",
       "\n",
       "     BIO1  ...  BIO4  BIO5  BIO6  BIO7  BIO8  BIO9_1  BIO10  BIO11  BIO12  \\\n",
       "0       4  ...     2     3     3     2     3    3.11      5      3      3   \n",
       "1       5  ...     2     5     1     2     1    3.53      5      5      5   \n",
       "2       3  ...     2     3     2     1     3    3.00      3      5      5   \n",
       "3       3  ...     2     4     2     3     3    2.50      3      2      3   \n",
       "4       1  ...     1     3     1     1     1    3.93      5      3      3   \n",
       "..    ...  ...   ...   ...   ...   ...   ...     ...    ...    ...    ...   \n",
       "236     1  ...     2     4     1     1     1    2.99      3      3      1   \n",
       "237     1  ...     2     5     2     4     5    3.74      6      3      3   \n",
       "238     3  ...     3     5     2     1     2    3.00      3      3      3   \n",
       "239     4  ...     2     5     2     5     1    4.00      8      3      2   \n",
       "240     4  ...     5     4     2     3     2    3.06      5      2      2   \n",
       "\n",
       "     BIO13  \n",
       "0        3  \n",
       "1        5  \n",
       "2        5  \n",
       "3        5  \n",
       "4        3  \n",
       "..     ...  \n",
       "236      5  \n",
       "237      5  \n",
       "238      5  \n",
       "239      5  \n",
       "240      1  \n",
       "\n",
       "[241 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data_study2.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51e9581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y=data['MOAQ']\n",
    "X=data.drop('MOAQ', axis=1)\n",
    "X_train, X_test, y_train, y_test= train_test_split(\n",
    "                                                X, y,\n",
    "                                                test_size=0.2,\n",
    "                                                random_state=53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88dbc2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.44867674298929133\n",
      "   Feature  Coefficient\n",
      "3     SPOS     0.355633\n",
      "0       TI    -0.327215\n",
      "5      ACS     0.305492\n",
      "16  BIO9_1     0.184857\n",
      "1      EES     0.171100\n",
      "11    BIO4     0.087171\n",
      "9     BIO2     0.087111\n",
      "4      BFI    -0.085561\n",
      "18   BIO11     0.048370\n",
      "20   BIO13     0.045576\n",
      "10    BIO3    -0.044642\n",
      "6      NCS    -0.035523\n",
      "12    BIO5     0.032321\n",
      "14    BIO7     0.031316\n",
      "15    BIO8    -0.029762\n",
      "8     BIO1    -0.028691\n",
      "13    BIO6     0.019139\n",
      "2     JIMS     0.015946\n",
      "7     GSOI     0.014350\n",
      "17   BIO10     0.011308\n",
      "19   BIO12    -0.000810\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "#X_train = np.array(X_train).reshape(-1,1)\n",
    "#y_train = np.array(y_train).reshape(-1,1)\n",
    "\n",
    "#X_test = np.array(X_test).reshape(-1,1)\n",
    "#y_test = np.array(y_test).reshape(-1,1)\n",
    "# Initialize and fit the linear regression model\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_lin = reg.predict(X_test)\n",
    "\n",
    "# Computing RMSE\n",
    "rmse_reg = np.sqrt(mean_squared_error(y_test, y_pred_lin))\n",
    "print(f\"RMSE: {rmse_reg}\")\n",
    "\n",
    "# Extract coefficients\n",
    "coefficients = reg.coef_\n",
    "# If X_train is a DataFrame, we can use column names directly\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Create a DataFrame to view the coefficients and feature names\n",
    "coeff_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefficients.flatten()})\n",
    "\n",
    "# Sort the DataFrame by the absolute values of the coefficients to see the most important features\n",
    "coeff_df = coeff_df.reindex(coeff_df.Coefficient.abs().sort_values(ascending=False).index)\n",
    "print(coeff_df)\n",
    "coeff_df.to_csv(\"lm_coeff_importance.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a4a1d4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
      "RMSE: 0.41763701690038324\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Define the parameter grid for XGBoost\n",
    "param_grid = {\n",
    "    'max_depth': range(1, 5),\n",
    "    'learning_rate': [0.005, 0.05, 0.5]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with XGBoost Regressor\n",
    "grid = GridSearchCV(xgb.XGBRegressor(random_state=0),\n",
    "                    param_grid=param_grid, cv=10, verbose=1, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Train the model on the training dataset\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing dataset\n",
    "y_pred_xgb = grid.predict(X_test)\n",
    "\n",
    "# Computing RMSE\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
    "print(f\"RMSE: {rmse_xgb}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ef48b979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diego\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 14.4416 - mean_squared_error: 14.4416  \n",
      "Epoch 2/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6911 - mean_squared_error: 1.6911 \n",
      "Epoch 3/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.0373 - mean_squared_error: 2.0373 \n",
      "Epoch 4/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5697 - mean_squared_error: 0.5697 \n",
      "Epoch 5/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8606 - mean_squared_error: 0.8606 \n",
      "Epoch 6/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5423 - mean_squared_error: 0.5423 \n",
      "Epoch 7/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4351 - mean_squared_error: 0.4351 \n",
      "Epoch 8/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3752 - mean_squared_error: 0.3752 \n",
      "Epoch 9/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3839 - mean_squared_error: 0.3839 \n",
      "Epoch 10/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2911 - mean_squared_error: 0.2911 \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "RMSE: 0.4381824036482006\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Define a simple neural network model for regression\n",
    "model = Sequential([\n",
    "    Dense(128, input_shape=(X_train.shape[1],), activation='relu'),  # Input layer with ReLU activation\n",
    "    Dense(64, activation='relu'),  # Hidden layer with ReLU activation\n",
    "    Dense(1)  # Output layer for regression (no activation function)\n",
    "])\n",
    "\n",
    "# Compile the model with optimizer and loss function suitable for regression\n",
    "model.compile(optimizer='adam', \n",
    "              loss='mean_squared_error',  # Change the loss function to MSE for regression\n",
    "              metrics=['mean_squared_error'])  # Change the metric to MSE\n",
    "\n",
    "# Train the model on the training dataset\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "# Make predictions on the testing dataset\n",
    "y_pred_nn = model.predict(X_test)\n",
    "\n",
    "# Computing RMSE\n",
    "rmse_nn = np.sqrt(mean_squared_error(y_test, y_pred_nn))\n",
    "print(f\"RMSE: {rmse_nn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "219c0cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "RMSE: 0.4543032747468956\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Define the pipeline with SVR instead of LinearSVC\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # It's common to scale inputs for SVM\n",
    "    ('svr', SVR())  # Use SVR for regression\n",
    "])\n",
    "\n",
    "# Define a parameter grid adapted for SVR\n",
    "param_grid = {\n",
    "    'svr__kernel': ['linear', 'poly', 'rbf'],  # SVR kernels\n",
    "    'svr__C': [0.01, 0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'svr__epsilon': [0.001, 0.01, 0.1, 1]  # Epsilon in the epsilon-SVR model\n",
    "}\n",
    "\n",
    "# Initialize RandomizedSearchCV with the SVR estimator and the parameter grid\n",
    "grid = RandomizedSearchCV(pipeline, param_grid, verbose=3, cv=10, n_jobs=-1)\n",
    "\n",
    "# Train the model on the training dataset\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing dataset using the best model found\n",
    "pred_svr = grid.predict(X_test)\n",
    "\n",
    "# Computing RMSE\n",
    "rmse_svr = np.sqrt(mean_squared_error(y_test, pred_svr))\n",
    "print(f\"RMSE: {rmse_svr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "385c5b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "RMSE: 0.4257038436686448\n",
      "   Feature  Importance\n",
      "3     SPOS    0.469608\n",
      "5      ACS    0.211012\n",
      "1      EES    0.109415\n",
      "2     JIMS    0.021177\n",
      "6      NCS    0.020849\n",
      "18   BIO11    0.020445\n",
      "4      BFI    0.017852\n",
      "7     GSOI    0.014718\n",
      "16  BIO9_1    0.014291\n",
      "0       TI    0.013632\n",
      "9     BIO2    0.013516\n",
      "12    BIO5    0.013181\n",
      "20   BIO13    0.013154\n",
      "19   BIO12    0.009077\n",
      "17   BIO10    0.007650\n",
      "11    BIO4    0.006592\n",
      "15    BIO8    0.006270\n",
      "10    BIO3    0.005191\n",
      "14    BIO7    0.004568\n",
      "8     BIO1    0.003979\n",
      "13    BIO6    0.003822\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Adjusting the parameter grid for RandomForestRegressor\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 200],  # Number of trees in the forest\n",
    "    'max_depth': range(1, 5)  # Maximum depth of the tree\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with the RandomForestRegressor and the parameter grid\n",
    "grid = GridSearchCV(RandomForestRegressor(random_state=0),\n",
    "                    param_grid=param_grid, cv=10, verbose=1, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit to the training data\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing dataset\n",
    "y_pred_rf = grid.predict(X_test)\n",
    "\n",
    "# Computing RMSE\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "print(f\"RMSE: {rmse_rf}\")\n",
    "\n",
    "# Extract the best estimator\n",
    "best_rf = grid.best_estimator_\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = best_rf.feature_importances_\n",
    "\n",
    "# Assuming X_train is a DataFrame, get feature names\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Create a DataFrame to view the feature importances\n",
    "features_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "\n",
    "# Sort the DataFrame by the importance of features\n",
    "features_df.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "\n",
    "# Print sorted feature importances\n",
    "print(features_df)\n",
    "features_df.to_csv(\"rfjs_coeff_importance.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cb546b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataset with the model names and their corresponding AUC scores\n",
    "data = {\n",
    "    \"Model\": [\"Logistic Regression\", \"XGBoost\", \"Neural Network\", \"SVM\", \"Random Forest\"],\n",
    "    \"RMSE\": [rmse_reg, rmse_xgb, rmse_nn, rmse_svr, rmse_rf]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Writing the dataset to a .csv file\n",
    "csv_file_path = \"ALL_model_rmse_scores.csv\"  # Specify your desired path and filename\n",
    "df.to_csv(csv_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
