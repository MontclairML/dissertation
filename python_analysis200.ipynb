{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f54435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e851580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DLEAVING</th>\n",
       "      <th>workXP</th>\n",
       "      <th>workUnit</th>\n",
       "      <th>workOffice</th>\n",
       "      <th>workOrg</th>\n",
       "      <th>workSuper</th>\n",
       "      <th>leadership</th>\n",
       "      <th>workSat</th>\n",
       "      <th>DEI</th>\n",
       "      <th>employeeXP</th>\n",
       "      <th>flexibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46608</th>\n",
       "      <td>1</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11518</th>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>3.357143</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80411</th>\n",
       "      <td>0</td>\n",
       "      <td>3.615385</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23295</th>\n",
       "      <td>0</td>\n",
       "      <td>4.230769</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40034</th>\n",
       "      <td>1</td>\n",
       "      <td>3.461538</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50361</th>\n",
       "      <td>1</td>\n",
       "      <td>3.076923</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105677</th>\n",
       "      <td>0</td>\n",
       "      <td>4.692308</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>1</td>\n",
       "      <td>4.923077</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97678</th>\n",
       "      <td>1</td>\n",
       "      <td>4.076923</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43032</th>\n",
       "      <td>0</td>\n",
       "      <td>4.230769</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DLEAVING    workXP  workUnit  workOffice  workOrg  workSuper  \\\n",
       "46608          1  5.000000       4.8         5.0      4.9        5.0   \n",
       "11518          1  4.000000       3.9         3.7      3.7        4.6   \n",
       "80411          0  3.615385       4.4         3.8      3.8        4.8   \n",
       "23295          0  4.230769       4.5         3.6      3.8        4.5   \n",
       "40034          1  3.461538       3.5         3.5      4.1        4.3   \n",
       "...          ...       ...       ...         ...      ...        ...   \n",
       "50361          1  3.076923       3.8         3.4      3.3        3.9   \n",
       "105677         0  4.692308       4.4         4.7      3.7        5.0   \n",
       "651            1  4.923077       4.8         4.9      4.3        4.9   \n",
       "97678          1  4.076923       4.1         3.8      4.7        4.8   \n",
       "43032          0  4.230769       4.6         4.7      4.5        4.8   \n",
       "\n",
       "        leadership   workSat       DEI  employeeXP  flexibility  \n",
       "46608          4.9  5.000000  5.000000         5.0          3.6  \n",
       "11518          4.1  4.166667  3.357143         4.6          3.1  \n",
       "80411          3.4  4.000000  4.000000         3.6          3.7  \n",
       "23295          4.1  3.666667  4.000000         3.2          3.2  \n",
       "40034          3.6  4.000000  3.928571         4.2          3.0  \n",
       "...            ...       ...       ...         ...          ...  \n",
       "50361          3.6  3.666667  3.142857         3.2          2.8  \n",
       "105677         3.5  4.500000  4.714286         5.0          3.3  \n",
       "651            3.5  4.500000  4.500000         4.4          2.9  \n",
       "97678          3.5  4.000000  4.000000         4.0          3.2  \n",
       "43032          4.4  4.666667  4.500000         5.0          3.3  \n",
       "\n",
       "[200 rows x 11 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data_cleaned.csv\")\n",
    "data = data.sample(n=200, random_state=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b280160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y=data['DLEAVING']\n",
    "X=data.iloc[:, -10:]\n",
    "X_train, X_test, y_train, y_test= train_test_split(\n",
    "                                                X, y,\n",
    "                                                test_size=0.33,\n",
    "                                                random_state=53)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d019597f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.56      0.57        18\n",
      "           1       0.84      0.85      0.85        48\n",
      "\n",
      "    accuracy                           0.77        66\n",
      "   macro avg       0.71      0.70      0.71        66\n",
      "weighted avg       0.77      0.77      0.77        66\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "reg = LogisticRegression().fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "deb89002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.33      0.44        18\n",
      "           1       0.79      0.94      0.86        48\n",
      "\n",
      "    accuracy                           0.77        66\n",
      "   macro avg       0.73      0.64      0.65        66\n",
      "weighted avg       0.76      0.77      0.74        66\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "\n",
    "param_grid = {'max_depth':range(1, 5),\n",
    "                'learning_rate':(0.005, 0.05, 0.5)}\n",
    " \n",
    "grid = GridSearchCV(xgb.XGBClassifier(random_state=0), \n",
    "                    param_grid=param_grid, cv=10, verbose=1, scoring='accuracy')\n",
    "    \n",
    "grid.fit(X_train, y_train)\n",
    "pred1 = grid.predict(X_test)\n",
    "print (classification_report(y_test,pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "796361e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diego\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6383 - loss: 0.6330  \n",
      "Epoch 2/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6592 - loss: 0.6406 \n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6186 - loss: 0.6493 \n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7188 - loss: 0.6068 \n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6721 - loss: 0.6096 \n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6590 - loss: 0.6348 \n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7350 - loss: 0.6129 \n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7440 - loss: 0.5700 \n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6796 - loss: 0.6149 \n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6962 - loss: 0.5751 \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.50      0.49        18\n",
      "           1       0.81      0.79      0.80        48\n",
      "\n",
      "    accuracy                           0.71        66\n",
      "   macro avg       0.64      0.65      0.64        66\n",
      "weighted avg       0.72      0.71      0.71        66\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Define a simple neural network model for binary classification\n",
    "model = Sequential([\n",
    "    Dense(128, input_shape=(X_train.shape[1],), activation='relu'),  # Input layer with ReLU activation\n",
    "    Dense(64, activation='relu'),  # Hidden layer with ReLU activation\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model with optimizer, loss function, and metrics for binary classification\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model on the training dataset\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "# Make predictions on the testing dataset\n",
    "pred_probs = model.predict(X_test)\n",
    "pred_nn = np.round(pred_probs).astype(int)  # Convert probabilities to binary class labels\n",
    "\n",
    "# Generate a classification report to evaluate the model\n",
    "print(classification_report(y_test, pred_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72c6578b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "[CV 1/10] END clf__C=0.1, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.01;, score=0.571 total time=   0.0s\n",
      "[CV 2/10] END clf__C=0.1, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.01;, score=0.643 total time=   0.0s\n",
      "[CV 3/10] END clf__C=0.1, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.01;, score=0.714 total time=   0.0s\n",
      "[CV 4/10] END clf__C=0.1, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.01;, score=0.857 total time=   0.0s\n",
      "[CV 5/10] END clf__C=0.1, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.01;, score=0.769 total time=   0.0s\n",
      "[CV 6/10] END clf__C=0.1, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.01;, score=0.692 total time=   0.0s\n",
      "[CV 7/10] END clf__C=0.1, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.01;, score=0.923 total time=   0.0s\n",
      "[CV 8/10] END clf__C=0.1, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.01;, score=0.692 total time=   0.0s\n",
      "[CV 9/10] END clf__C=0.1, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.01;, score=0.769 total time=   0.0s\n",
      "[CV 10/10] END clf__C=0.1, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.01;, score=0.538 total time=   0.0s\n",
      "[CV 1/10] END clf__C=1, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.0001;, score=0.571 total time=   0.0s\n",
      "[CV 2/10] END clf__C=1, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.0001;, score=0.643 total time=   0.0s\n",
      "[CV 3/10] END clf__C=1, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.0001;, score=0.857 total time=   0.0s\n",
      "[CV 4/10] END clf__C=1, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.0001;, score=0.786 total time=   0.0s\n",
      "[CV 5/10] END clf__C=1, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.0001;, score=0.769 total time=   0.0s\n",
      "[CV 6/10] END clf__C=1, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.0001;, score=0.615 total time=   0.0s\n",
      "[CV 7/10] END clf__C=1, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.0001;, score=0.923 total time=   0.0s\n",
      "[CV 8/10] END clf__C=1, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.0001;, score=0.923 total time=   0.0s\n",
      "[CV 9/10] END clf__C=1, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.0001;, score=0.692 total time=   0.0s\n",
      "[CV 10/10] END clf__C=1, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.0001;, score=0.538 total time=   0.0s\n",
      "[CV 1/10] END clf__C=10, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l1, clf__tol=0.01;, score=0.571 total time=   0.0s\n",
      "[CV 2/10] END clf__C=10, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l1, clf__tol=0.01;, score=0.643 total time=   0.0s\n",
      "[CV 3/10] END clf__C=10, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l1, clf__tol=0.01;, score=0.857 total time=   0.0s\n",
      "[CV 4/10] END clf__C=10, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l1, clf__tol=0.01;, score=0.857 total time=   0.0s\n",
      "[CV 5/10] END clf__C=10, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l1, clf__tol=0.01;, score=0.846 total time=   0.0s\n",
      "[CV 6/10] END clf__C=10, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l1, clf__tol=0.01;, score=0.615 total time=   0.0s\n",
      "[CV 7/10] END clf__C=10, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l1, clf__tol=0.01;, score=0.923 total time=   0.0s\n",
      "[CV 8/10] END clf__C=10, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l1, clf__tol=0.01;, score=0.923 total time=   0.0s\n",
      "[CV 9/10] END clf__C=10, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l1, clf__tol=0.01;, score=0.692 total time=   0.0s\n",
      "[CV 10/10] END clf__C=10, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l1, clf__tol=0.01;, score=0.538 total time=   0.0s\n",
      "[CV 1/10] END clf__C=0.01, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.643 total time=   0.0s\n",
      "[CV 2/10] END clf__C=0.01, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.714 total time=   0.0s\n",
      "[CV 3/10] END clf__C=0.01, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.643 total time=   0.0s\n",
      "[CV 4/10] END clf__C=0.01, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.714 total time=   0.0s\n",
      "[CV 5/10] END clf__C=0.01, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.692 total time=   0.0s\n",
      "[CV 6/10] END clf__C=0.01, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.692 total time=   0.0s\n",
      "[CV 7/10] END clf__C=0.01, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.692 total time=   0.0s\n",
      "[CV 8/10] END clf__C=0.01, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.615 total time=   0.0s\n",
      "[CV 9/10] END clf__C=0.01, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.692 total time=   0.0s\n",
      "[CV 10/10] END clf__C=0.01, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.692 total time=   0.0s\n",
      "[CV 1/10] END clf__C=1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.0001;, score=0.571 total time=   0.0s\n",
      "[CV 2/10] END clf__C=1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.0001;, score=0.643 total time=   0.0s\n",
      "[CV 3/10] END clf__C=1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.0001;, score=0.857 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diego\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\diego\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\diego\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\diego\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END clf__C=1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.0001;, score=0.857 total time=   0.0s\n",
      "[CV 5/10] END clf__C=1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.0001;, score=0.769 total time=   0.0s\n",
      "[CV 6/10] END clf__C=1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.0001;, score=0.615 total time=   0.0s\n",
      "[CV 7/10] END clf__C=1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.0001;, score=0.923 total time=   0.0s\n",
      "[CV 8/10] END clf__C=1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.0001;, score=0.923 total time=   0.0s\n",
      "[CV 9/10] END clf__C=1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.0001;, score=0.692 total time=   0.0s\n",
      "[CV 10/10] END clf__C=1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.0001;, score=0.538 total time=   0.0s\n",
      "[CV 1/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.0001;, score=0.571 total time=   0.0s\n",
      "[CV 2/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.0001;, score=0.643 total time=   0.0s\n",
      "[CV 3/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.0001;, score=0.857 total time=   0.0s\n",
      "[CV 4/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.0001;, score=0.857 total time=   0.0s\n",
      "[CV 5/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.0001;, score=0.846 total time=   0.0s\n",
      "[CV 6/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.0001;, score=0.615 total time=   0.0s\n",
      "[CV 7/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.0001;, score=0.923 total time=   0.0s\n",
      "[CV 8/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.0001;, score=0.923 total time=   0.0s\n",
      "[CV 9/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.0001;, score=0.692 total time=   0.0s\n",
      "[CV 10/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.0001;, score=0.538 total time=   0.0s\n",
      "[CV 1/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.001;, score=0.571 total time=   0.0s\n",
      "[CV 2/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.001;, score=0.643 total time=   0.0s\n",
      "[CV 3/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.001;, score=0.857 total time=   0.0s\n",
      "[CV 4/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.001;, score=0.857 total time=   0.0s\n",
      "[CV 5/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.001;, score=0.846 total time=   0.0s\n",
      "[CV 6/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.001;, score=0.615 total time=   0.0s\n",
      "[CV 7/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.001;, score=0.923 total time=   0.0s\n",
      "[CV 8/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.001;, score=0.923 total time=   0.0s\n",
      "[CV 9/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.001;, score=0.692 total time=   0.0s\n",
      "[CV 10/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.001;, score=0.538 total time=   0.0s\n",
      "[CV 1/10] END clf__C=0.1, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.571 total time=   0.0s\n",
      "[CV 2/10] END clf__C=0.1, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.643 total time=   0.0s\n",
      "[CV 3/10] END clf__C=0.1, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.714 total time=   0.0s\n",
      "[CV 4/10] END clf__C=0.1, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.857 total time=   0.0s\n",
      "[CV 5/10] END clf__C=0.1, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.769 total time=   0.0s\n",
      "[CV 6/10] END clf__C=0.1, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.692 total time=   0.0s\n",
      "[CV 7/10] END clf__C=0.1, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.923 total time=   0.0s\n",
      "[CV 8/10] END clf__C=0.1, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.692 total time=   0.0s\n",
      "[CV 9/10] END clf__C=0.1, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.769 total time=   0.0s\n",
      "[CV 10/10] END clf__C=0.1, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.01;, score=0.538 total time=   0.0s\n",
      "[CV 1/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.001;, score=0.571 total time=   0.0s\n",
      "[CV 2/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.001;, score=0.643 total time=   0.0s\n",
      "[CV 3/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.001;, score=0.857 total time=   0.0s\n",
      "[CV 4/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.001;, score=0.857 total time=   0.0s\n",
      "[CV 5/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.001;, score=0.846 total time=   0.0s\n",
      "[CV 6/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.001;, score=0.615 total time=   0.0s\n",
      "[CV 7/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.001;, score=0.923 total time=   0.0s\n",
      "[CV 8/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.001;, score=0.923 total time=   0.0s\n",
      "[CV 9/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.001;, score=0.692 total time=   0.0s\n",
      "[CV 10/10] END clf__C=100, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.001;, score=0.538 total time=   0.0s\n",
      "[CV 1/10] END clf__C=1, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.01;, score=0.571 total time=   0.0s\n",
      "[CV 2/10] END clf__C=1, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.01;, score=0.643 total time=   0.0s\n",
      "[CV 3/10] END clf__C=1, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.01;, score=0.714 total time=   0.0s\n",
      "[CV 4/10] END clf__C=1, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.01;, score=0.857 total time=   0.0s\n",
      "[CV 5/10] END clf__C=1, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.01;, score=0.769 total time=   0.0s\n",
      "[CV 6/10] END clf__C=1, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.01;, score=0.615 total time=   0.0s\n",
      "[CV 7/10] END clf__C=1, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.01;, score=0.923 total time=   0.0s\n",
      "[CV 8/10] END clf__C=1, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.01;, score=0.846 total time=   0.0s\n",
      "[CV 9/10] END clf__C=1, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.01;, score=0.692 total time=   0.0s\n",
      "[CV 10/10] END clf__C=1, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l2, clf__tol=0.01;, score=0.538 total time=   0.0s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.61      0.59        18\n",
      "           1       0.85      0.83      0.84        48\n",
      "\n",
      "    accuracy                           0.77        66\n",
      "   macro avg       0.72      0.72      0.72        66\n",
      "weighted avg       0.78      0.77      0.77        66\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "pipeline = Pipeline([\n",
    "    ('clf', LinearSVC(dual=False))  # 'clf' is the name we give to the LinearSVC step\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Define a very simple parameter grid, could be expanded based on need\n",
    "param_grid = {\n",
    "    'clf__penalty': ['l1', 'l2'],\n",
    "    'clf__loss': ['squared_hinge'],\n",
    "    'clf__tol': [1e-4, 1e-3, 1e-2],\n",
    "    'clf__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'clf__max_iter': [1000, 2000, 3000],\n",
    "    'clf__intercept_scaling': [1, 10, 100]\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize GridSearchCV with the SVC estimator and the simple param grid\n",
    "grid = RandomizedSearchCV(pipeline, param_grid, verbose=3, cv=10)\n",
    "\n",
    "# Train the model on the training dataset\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing dataset using the best model found\n",
    "pred_svm = grid.predict(X_test)\n",
    "\n",
    "# Generate a classification report to evaluate the model\n",
    "print(classification_report(y_test, pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e7f890e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.56      0.57        18\n",
      "           1       0.84      0.85      0.85        48\n",
      "\n",
      "    accuracy                           0.77        66\n",
      "   macro avg       0.71      0.70      0.71        66\n",
      "weighted avg       0.77      0.77      0.77        66\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Adjusting the parameter grid for RandomForestClassifier\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 200],  # Number of trees in the forest\n",
    "    'max_depth': range(1, 5)  # Maximum depth of the tree\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(RandomForestClassifier(random_state=0),\n",
    "                    param_grid=param_grid, cv=10, verbose=1, scoring='accuracy')\n",
    "\n",
    "# Fit to the training data\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "pred1 = grid.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, pred1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
