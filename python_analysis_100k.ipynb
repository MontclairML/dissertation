{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f54435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e851580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DLEAVING</th>\n",
       "      <th>workXP</th>\n",
       "      <th>workUnit</th>\n",
       "      <th>workOffice</th>\n",
       "      <th>workOrg</th>\n",
       "      <th>workSuper</th>\n",
       "      <th>leadership</th>\n",
       "      <th>workSat</th>\n",
       "      <th>DEI</th>\n",
       "      <th>employeeXP</th>\n",
       "      <th>flexibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.923077</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.615385</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.785714</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4.692308</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3.307692</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.357143</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4.923077</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111128</th>\n",
       "      <td>1</td>\n",
       "      <td>4.153846</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111129</th>\n",
       "      <td>1</td>\n",
       "      <td>3.615385</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111130</th>\n",
       "      <td>1</td>\n",
       "      <td>3.461538</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.785714</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111131</th>\n",
       "      <td>1</td>\n",
       "      <td>4.461538</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111132</th>\n",
       "      <td>1</td>\n",
       "      <td>4.461538</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111133 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DLEAVING    workXP  workUnit  workOffice  workOrg  workSuper  \\\n",
       "0              1  3.923077       3.9         3.8      3.4        4.8   \n",
       "1              1  4.615385       3.7         3.4      4.1        4.9   \n",
       "2              0  4.692308       5.0         4.6      5.0        5.0   \n",
       "3              0  3.307692       2.6         3.1      2.8        3.6   \n",
       "4              1  4.923077       5.0         4.6      4.6        5.0   \n",
       "...          ...       ...       ...         ...      ...        ...   \n",
       "111128         1  4.153846       4.7         4.0      4.9        4.0   \n",
       "111129         1  3.615385       4.1         3.2      3.8        3.5   \n",
       "111130         1  3.461538       3.7         3.6      3.4        3.0   \n",
       "111131         1  4.461538       4.3         4.1      4.2        4.4   \n",
       "111132         1  4.461538       4.4         4.2      5.0        4.9   \n",
       "\n",
       "        leadership   workSat       DEI  employeeXP  flexibility  \n",
       "0              2.5  3.833333  4.000000         4.8          2.7  \n",
       "1              4.0  4.500000  3.785714         4.8          2.9  \n",
       "2              5.0  5.000000  5.000000         5.0          3.3  \n",
       "3              2.0  2.500000  2.357143         4.8          2.1  \n",
       "4              4.8  5.000000  5.000000         4.8          3.3  \n",
       "...            ...       ...       ...         ...          ...  \n",
       "111128         4.5  4.333333  4.428571         5.0          3.3  \n",
       "111129         3.1  3.000000  4.000000         2.6          2.9  \n",
       "111130         3.3  3.333333  3.785714         3.4          2.3  \n",
       "111131         4.6  4.666667  4.571429         5.0          3.0  \n",
       "111132         4.7  4.833333  5.000000         5.0          3.2  \n",
       "\n",
       "[111133 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data_cleaned.csv\")\n",
    "#data = data.sample(n=100000, random_state=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b280160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y=data['DLEAVING']\n",
    "X=data.iloc[:, -10:]\n",
    "X_train, X_test, y_train, y_test= train_test_split(\n",
    "                                                X, y,\n",
    "                                                test_size=0.33,\n",
    "                                                random_state=53)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d019597f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.45      0.55     11812\n",
      "           1       0.78      0.91      0.84     24862\n",
      "\n",
      "    accuracy                           0.76     36674\n",
      "   macro avg       0.74      0.68      0.69     36674\n",
      "weighted avg       0.75      0.76      0.75     36674\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "reg = LogisticRegression().fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06108f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8c3dc th {\n",
       "  font-size: 12pt;\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8c3dc\">\n",
       "  <caption>Classification Report in APA Style</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8c3dc_level0_col0\" class=\"col_heading level0 col0\" >precision</th>\n",
       "      <th id=\"T_8c3dc_level0_col1\" class=\"col_heading level0 col1\" >recall</th>\n",
       "      <th id=\"T_8c3dc_level0_col2\" class=\"col_heading level0 col2\" >f1-score</th>\n",
       "      <th id=\"T_8c3dc_level0_col3\" class=\"col_heading level0 col3\" >support</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" > </th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8c3dc_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_8c3dc_row0_col0\" class=\"data row0 col0\" >0.710000</td>\n",
       "      <td id=\"T_8c3dc_row0_col1\" class=\"data row0 col1\" >0.450000</td>\n",
       "      <td id=\"T_8c3dc_row0_col2\" class=\"data row0 col2\" >0.530000</td>\n",
       "      <td id=\"T_8c3dc_row0_col3\" class=\"data row0 col3\" >59348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8c3dc_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_8c3dc_row1_col0\" class=\"data row1 col0\" >0.780000</td>\n",
       "      <td id=\"T_8c3dc_row1_col1\" class=\"data row1 col1\" >0.910000</td>\n",
       "      <td id=\"T_8c3dc_row1_col2\" class=\"data row1 col2\" >0.830000</td>\n",
       "      <td id=\"T_8c3dc_row1_col3\" class=\"data row1 col3\" >124719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8c3dc_level0_row2\" class=\"row_heading level0 row2\" >accuracy</th>\n",
       "      <td id=\"T_8c3dc_row2_col0\" class=\"data row2 col0\" ></td>\n",
       "      <td id=\"T_8c3dc_row2_col1\" class=\"data row2 col1\" >0.750000</td>\n",
       "      <td id=\"T_8c3dc_row2_col2\" class=\"data row2 col2\" ></td>\n",
       "      <td id=\"T_8c3dc_row2_col3\" class=\"data row2 col3\" >184067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8c3dc_level0_row3\" class=\"row_heading level0 row3\" >macro avg</th>\n",
       "      <td id=\"T_8c3dc_row3_col0\" class=\"data row3 col0\" >0.740000</td>\n",
       "      <td id=\"T_8c3dc_row3_col1\" class=\"data row3 col1\" >0.670000</td>\n",
       "      <td id=\"T_8c3dc_row3_col2\" class=\"data row3 col2\" >0.680000</td>\n",
       "      <td id=\"T_8c3dc_row3_col3\" class=\"data row3 col3\" >184067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8c3dc_level0_row4\" class=\"row_heading level0 row4\" >weighted avg</th>\n",
       "      <td id=\"T_8c3dc_row4_col0\" class=\"data row4 col0\" >0.750000</td>\n",
       "      <td id=\"T_8c3dc_row4_col1\" class=\"data row4 col1\" >0.750000</td>\n",
       "      <td id=\"T_8c3dc_row4_col2\" class=\"data row4 col2\" >0.740000</td>\n",
       "      <td id=\"T_8c3dc_row4_col3\" class=\"data row4 col3\" >184067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23b2a780d10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given classification report\n",
    "data = {\n",
    "    ' ': ['0', '1', 'accuracy', 'macro avg', 'weighted avg'],\n",
    "    'precision': [0.71, 0.78, '', 0.74, 0.75],\n",
    "    'recall': [0.45, 0.91, 0.75, 0.67, 0.75],\n",
    "    'f1-score': [0.53, 0.83, '', 0.68, 0.74],\n",
    "    'support': [59348, 124719, 184067, 184067, 184067]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Setting the index\n",
    "df.set_index(' ', inplace=True)\n",
    "\n",
    "# Display the DataFrame in a \"nice table\"\n",
    "df.style.set_table_styles(\n",
    "    [{'selector': 'th', 'props': [('font-size', '12pt'), ('text-align', 'center')]}]\n",
    ").set_caption(\"Classification Report in APA Style\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deb89002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.48      0.57     11812\n",
      "           1       0.78      0.90      0.84     24862\n",
      "\n",
      "    accuracy                           0.77     36674\n",
      "   macro avg       0.74      0.69      0.70     36674\n",
      "weighted avg       0.76      0.77      0.75     36674\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "\n",
    "param_grid = {'max_depth':range(1, 5),\n",
    "                'learning_rate':(0.005, 0.05, 0.5)}\n",
    " \n",
    "grid = GridSearchCV(xgb.XGBClassifier(random_state=0), \n",
    "                    param_grid=param_grid, cv=10, verbose=1, scoring='accuracy')\n",
    "    \n",
    "grid.fit(X_train, y_train)\n",
    "pred1 = grid.predict(X_test)\n",
    "print (classification_report(y_test,pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "796361e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diego\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2327/2327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 853us/step - accuracy: 0.7436 - loss: 0.5345\n",
      "Epoch 2/10\n",
      "\u001b[1m2327/2327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 839us/step - accuracy: 0.7603 - loss: 0.5182\n",
      "Epoch 3/10\n",
      "\u001b[1m2327/2327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 834us/step - accuracy: 0.7633 - loss: 0.5146\n",
      "Epoch 4/10\n",
      "\u001b[1m2327/2327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 851us/step - accuracy: 0.7629 - loss: 0.5153\n",
      "Epoch 5/10\n",
      "\u001b[1m2327/2327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 860us/step - accuracy: 0.7628 - loss: 0.5135\n",
      "Epoch 6/10\n",
      "\u001b[1m2327/2327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 888us/step - accuracy: 0.7620 - loss: 0.5147\n",
      "Epoch 7/10\n",
      "\u001b[1m2327/2327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 867us/step - accuracy: 0.7609 - loss: 0.5154\n",
      "Epoch 8/10\n",
      "\u001b[1m2327/2327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 858us/step - accuracy: 0.7607 - loss: 0.5164\n",
      "Epoch 9/10\n",
      "\u001b[1m2327/2327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 863us/step - accuracy: 0.7635 - loss: 0.5134\n",
      "Epoch 10/10\n",
      "\u001b[1m2327/2327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 872us/step - accuracy: 0.7630 - loss: 0.5131\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.49      0.57     11812\n",
      "           1       0.79      0.90      0.84     24862\n",
      "\n",
      "    accuracy                           0.76     36674\n",
      "   macro avg       0.74      0.69      0.71     36674\n",
      "weighted avg       0.76      0.76      0.75     36674\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Define a simple neural network model for binary classification\n",
    "model = Sequential([\n",
    "    Dense(128, input_shape=(X_train.shape[1],), activation='relu'),  # Input layer with ReLU activation\n",
    "    Dense(64, activation='relu'),  # Hidden layer with ReLU activation\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model with optimizer, loss function, and metrics for binary classification\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model on the training dataset\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "# Make predictions on the testing dataset\n",
    "pred_probs = model.predict(X_test)\n",
    "pred_nn = np.round(pred_probs).astype(int)  # Convert probabilities to binary class labels\n",
    "\n",
    "# Generate a classification report to evaluate the model\n",
    "print(classification_report(y_test, pred_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72c6578b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "[CV 1/10] END clf__C=1, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.001;, score=0.772 total time=   0.9s\n",
      "[CV 2/10] END clf__C=1, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.001;, score=0.768 total time=   1.0s\n",
      "[CV 3/10] END clf__C=1, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.001;, score=0.766 total time=   1.1s\n",
      "[CV 4/10] END clf__C=1, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.001;, score=0.753 total time=   0.9s\n",
      "[CV 5/10] END clf__C=1, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.001;, score=0.765 total time=   0.8s\n",
      "[CV 6/10] END clf__C=1, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.001;, score=0.761 total time=   0.9s\n",
      "[CV 7/10] END clf__C=1, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.001;, score=0.760 total time=   0.9s\n",
      "[CV 8/10] END clf__C=1, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.001;, score=0.760 total time=   0.9s\n",
      "[CV 9/10] END clf__C=1, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.001;, score=0.758 total time=   0.7s\n",
      "[CV 10/10] END clf__C=1, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.001;, score=0.758 total time=   1.0s\n",
      "[CV 1/10] END clf__C=1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l1, clf__tol=0.01;, score=0.772 total time=   0.4s\n",
      "[CV 2/10] END clf__C=1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l1, clf__tol=0.01;, score=0.767 total time=   0.4s\n",
      "[CV 3/10] END clf__C=1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l1, clf__tol=0.01;, score=0.766 total time=   0.3s\n",
      "[CV 4/10] END clf__C=1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l1, clf__tol=0.01;, score=0.754 total time=   0.3s\n",
      "[CV 5/10] END clf__C=1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l1, clf__tol=0.01;, score=0.766 total time=   0.4s\n",
      "[CV 6/10] END clf__C=1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l1, clf__tol=0.01;, score=0.761 total time=   0.3s\n",
      "[CV 7/10] END clf__C=1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l1, clf__tol=0.01;, score=0.760 total time=   0.4s\n",
      "[CV 8/10] END clf__C=1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l1, clf__tol=0.01;, score=0.761 total time=   0.4s\n",
      "[CV 9/10] END clf__C=1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l1, clf__tol=0.01;, score=0.757 total time=   0.2s\n",
      "[CV 10/10] END clf__C=1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=1000, clf__penalty=l1, clf__tol=0.01;, score=0.758 total time=   0.3s\n",
      "[CV 1/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.01;, score=0.772 total time=   0.3s\n",
      "[CV 2/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.01;, score=0.768 total time=   0.4s\n",
      "[CV 3/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.01;, score=0.766 total time=   0.3s\n",
      "[CV 4/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.01;, score=0.754 total time=   0.3s\n",
      "[CV 5/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.01;, score=0.765 total time=   0.3s\n",
      "[CV 6/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.01;, score=0.761 total time=   0.3s\n",
      "[CV 7/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.01;, score=0.761 total time=   0.4s\n",
      "[CV 8/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.01;, score=0.761 total time=   0.4s\n",
      "[CV 9/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.01;, score=0.759 total time=   0.3s\n",
      "[CV 10/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.01;, score=0.758 total time=   0.3s\n",
      "[CV 1/10] END clf__C=100, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.0001;, score=0.772 total time=   0.1s\n",
      "[CV 2/10] END clf__C=100, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.0001;, score=0.767 total time=   0.0s\n",
      "[CV 3/10] END clf__C=100, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.0001;, score=0.766 total time=   0.0s\n",
      "[CV 4/10] END clf__C=100, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.0001;, score=0.753 total time=   0.1s\n",
      "[CV 5/10] END clf__C=100, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.0001;, score=0.766 total time=   0.1s\n",
      "[CV 6/10] END clf__C=100, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.0001;, score=0.761 total time=   0.1s\n",
      "[CV 7/10] END clf__C=100, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.0001;, score=0.760 total time=   0.1s\n",
      "[CV 8/10] END clf__C=100, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.0001;, score=0.760 total time=   0.0s\n",
      "[CV 9/10] END clf__C=100, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.0001;, score=0.757 total time=   0.1s\n",
      "[CV 10/10] END clf__C=100, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.0001;, score=0.758 total time=   0.1s\n",
      "[CV 1/10] END clf__C=100, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.001;, score=0.772 total time=   0.0s\n",
      "[CV 2/10] END clf__C=100, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.001;, score=0.767 total time=   0.0s\n",
      "[CV 3/10] END clf__C=100, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.001;, score=0.766 total time=   0.0s\n",
      "[CV 4/10] END clf__C=100, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.001;, score=0.753 total time=   0.0s\n",
      "[CV 5/10] END clf__C=100, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.001;, score=0.766 total time=   0.0s\n",
      "[CV 6/10] END clf__C=100, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.001;, score=0.761 total time=   0.0s\n",
      "[CV 7/10] END clf__C=100, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.001;, score=0.761 total time=   0.0s\n",
      "[CV 8/10] END clf__C=100, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.001;, score=0.760 total time=   0.0s\n",
      "[CV 9/10] END clf__C=100, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.001;, score=0.757 total time=   0.0s\n",
      "[CV 10/10] END clf__C=100, clf__intercept_scaling=100, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l2, clf__tol=0.001;, score=0.758 total time=   0.0s\n",
      "[CV 1/10] END clf__C=1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.001;, score=0.772 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/10] END clf__C=1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.001;, score=0.768 total time=   0.0s\n",
      "[CV 3/10] END clf__C=1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.001;, score=0.766 total time=   0.0s\n",
      "[CV 4/10] END clf__C=1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.001;, score=0.753 total time=   0.0s\n",
      "[CV 5/10] END clf__C=1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.001;, score=0.766 total time=   0.0s\n",
      "[CV 6/10] END clf__C=1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.001;, score=0.761 total time=   0.0s\n",
      "[CV 7/10] END clf__C=1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.001;, score=0.760 total time=   0.0s\n",
      "[CV 8/10] END clf__C=1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.001;, score=0.760 total time=   0.0s\n",
      "[CV 9/10] END clf__C=1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.001;, score=0.758 total time=   0.0s\n",
      "[CV 10/10] END clf__C=1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l2, clf__tol=0.001;, score=0.758 total time=   0.0s\n",
      "[CV 1/10] END clf__C=0.1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.001;, score=0.772 total time=   1.0s\n",
      "[CV 2/10] END clf__C=0.1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.001;, score=0.768 total time=   0.9s\n",
      "[CV 3/10] END clf__C=0.1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.001;, score=0.766 total time=   0.8s\n",
      "[CV 4/10] END clf__C=0.1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.001;, score=0.753 total time=   1.0s\n",
      "[CV 5/10] END clf__C=0.1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.001;, score=0.766 total time=   0.8s\n",
      "[CV 6/10] END clf__C=0.1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.001;, score=0.761 total time=   1.0s\n",
      "[CV 7/10] END clf__C=0.1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.001;, score=0.760 total time=   0.9s\n",
      "[CV 8/10] END clf__C=0.1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.001;, score=0.760 total time=   1.0s\n",
      "[CV 9/10] END clf__C=0.1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.001;, score=0.757 total time=   0.8s\n",
      "[CV 10/10] END clf__C=0.1, clf__intercept_scaling=10, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.001;, score=0.758 total time=   1.0s\n",
      "[CV 1/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.001;, score=0.772 total time=   0.8s\n",
      "[CV 2/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.001;, score=0.768 total time=   0.9s\n",
      "[CV 3/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.001;, score=0.766 total time=   1.0s\n",
      "[CV 4/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.001;, score=0.753 total time=   0.9s\n",
      "[CV 5/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.001;, score=0.766 total time=   0.8s\n",
      "[CV 6/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.001;, score=0.761 total time=   1.1s\n",
      "[CV 7/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.001;, score=0.760 total time=   1.0s\n",
      "[CV 8/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.001;, score=0.760 total time=   0.9s\n",
      "[CV 9/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.001;, score=0.757 total time=   0.9s\n",
      "[CV 10/10] END clf__C=100, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.001;, score=0.758 total time=   0.9s\n",
      "[CV 1/10] END clf__C=10, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.001;, score=0.772 total time=   0.9s\n",
      "[CV 2/10] END clf__C=10, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.001;, score=0.767 total time=   0.9s\n",
      "[CV 3/10] END clf__C=10, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.001;, score=0.766 total time=   0.9s\n",
      "[CV 4/10] END clf__C=10, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.001;, score=0.753 total time=   1.1s\n",
      "[CV 5/10] END clf__C=10, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.001;, score=0.766 total time=   0.8s\n",
      "[CV 6/10] END clf__C=10, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.001;, score=0.761 total time=   1.0s\n",
      "[CV 7/10] END clf__C=10, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.001;, score=0.760 total time=   0.9s\n",
      "[CV 8/10] END clf__C=10, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.001;, score=0.760 total time=   0.9s\n",
      "[CV 9/10] END clf__C=10, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.001;, score=0.757 total time=   0.9s\n",
      "[CV 10/10] END clf__C=10, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=3000, clf__penalty=l1, clf__tol=0.001;, score=0.758 total time=   0.8s\n",
      "[CV 1/10] END clf__C=0.01, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.001;, score=0.772 total time=   0.9s\n",
      "[CV 2/10] END clf__C=0.01, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.001;, score=0.767 total time=   1.0s\n",
      "[CV 3/10] END clf__C=0.01, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.001;, score=0.766 total time=   1.0s\n",
      "[CV 4/10] END clf__C=0.01, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.001;, score=0.753 total time=   0.8s\n",
      "[CV 5/10] END clf__C=0.01, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.001;, score=0.765 total time=   0.8s\n",
      "[CV 6/10] END clf__C=0.01, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.001;, score=0.761 total time=   0.8s\n",
      "[CV 7/10] END clf__C=0.01, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.001;, score=0.762 total time=   0.9s\n",
      "[CV 8/10] END clf__C=0.01, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.001;, score=0.760 total time=   0.8s\n",
      "[CV 9/10] END clf__C=0.01, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.001;, score=0.757 total time=   0.8s\n",
      "[CV 10/10] END clf__C=0.01, clf__intercept_scaling=1, clf__loss=squared_hinge, clf__max_iter=2000, clf__penalty=l1, clf__tol=0.001;, score=0.759 total time=   0.8s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.44      0.54     11812\n",
      "           1       0.77      0.92      0.84     24862\n",
      "\n",
      "    accuracy                           0.76     36674\n",
      "   macro avg       0.74      0.68      0.69     36674\n",
      "weighted avg       0.75      0.76      0.74     36674\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "pipeline = Pipeline([\n",
    "    ('clf', LinearSVC(dual=False))  # 'clf' is the name we give to the LinearSVC step\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Define a very simple parameter grid, could be expanded based on need\n",
    "param_grid = {\n",
    "    'clf__penalty': ['l1', 'l2'],\n",
    "    'clf__loss': ['squared_hinge'],\n",
    "    'clf__tol': [1e-4, 1e-3, 1e-2],\n",
    "    'clf__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'clf__max_iter': [1000, 2000, 3000],\n",
    "    'clf__intercept_scaling': [1, 10, 100]\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize GridSearchCV with the SVC estimator and the simple param grid\n",
    "grid = RandomizedSearchCV(pipeline, param_grid, verbose=3, cv=10)\n",
    "\n",
    "# Train the model on the training dataset\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing dataset using the best model found\n",
    "pred_svm = grid.predict(X_test)\n",
    "\n",
    "# Generate a classification report to evaluate the model\n",
    "print(classification_report(y_test, pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e7f890e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.43      0.53     11812\n",
      "           1       0.77      0.91      0.83     24862\n",
      "\n",
      "    accuracy                           0.76     36674\n",
      "   macro avg       0.73      0.67      0.68     36674\n",
      "weighted avg       0.75      0.76      0.74     36674\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Adjusting the parameter grid for RandomForestClassifier\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 200],  # Number of trees in the forest\n",
    "    'max_depth': range(1, 5)  # Maximum depth of the tree\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(RandomForestClassifier(random_state=0),\n",
    "                    param_grid=param_grid, cv=10, verbose=1, scoring='accuracy')\n",
    "\n",
    "# Fit to the training data\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "pred1 = grid.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, pred1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
